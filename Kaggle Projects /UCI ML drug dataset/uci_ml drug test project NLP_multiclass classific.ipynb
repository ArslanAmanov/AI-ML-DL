{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArslanAmanov/AI-ML-DL/blob/default-branch/Kaggle%20Projects%20/UCI%20ML%20drug%20dataset/uci_ml%20drug%20test%20project%20NLP_multiclass%20classific.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Kn3s60pgBkgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchvision"
      ],
      "metadata": {
        "id": "Mnajy7QoD_oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     !pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# else:\n",
        "#     print(\"No GPU available.\")"
      ],
      "metadata": {
        "id": "DsoHtULaEEm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "\n",
        "# print(torch.__version__)\n",
        "# print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "jw7ugylcEdFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5DfRK8dmBIEz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "\n",
        "#import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "\n",
        "from nltk import word_tokenize\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "#cross validation and metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "from sklearn.decomposition import PCA\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#UCI ML drug dataset\n",
        "\n",
        "#Importing the datasets and libraries\n",
        "url_1_test='https://raw.githubusercontent.com/ArslanAmanov/AI-ML-DL/default-branch/Kaggle%20Projects%20/UCI%20ML%20drug%20dataset/drugsComTest_raw.csv'\n",
        "url_2_train='https://raw.githubusercontent.com/ArslanAmanov/AI-ML-DL/default-branch/Kaggle%20Projects%20/UCI%20ML%20drug%20dataset/drugsComTrain_raw.csv'\n",
        "df1 = pd.read_csv(url_1_test)\n",
        "df2 = pd.read_csv(url_2_train)"
      ],
      "metadata": {
        "id": "dGQuz851DdwV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([df1,df2])[['review','condition']]"
      ],
      "metadata": {
        "id": "TPI86sYzGE6S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "8LtaYU5oGO4G",
        "outputId": "a448d36a-3588-4721-a918-1d23ccb09246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  \\\n",
              "0  \"I&#039;ve tried a few antidepressants over th...   \n",
              "1  \"My son has Crohn&#039;s disease and has done ...   \n",
              "2                      \"Quick reduction of symptoms\"   \n",
              "3  \"Contrave combines drugs that were used for al...   \n",
              "4  \"I have been on this birth control for one cyc...   \n",
              "\n",
              "                      condition  \n",
              "0                    Depression  \n",
              "1  Crohn's Disease, Maintenance  \n",
              "2       Urinary Tract Infection  \n",
              "3                   Weight Loss  \n",
              "4                 Birth Control  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96145a49-0620-40db-9f2a-1430fe46da79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
              "      <td>Depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
              "      <td>Crohn's Disease, Maintenance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Quick reduction of symptoms\"</td>\n",
              "      <td>Urinary Tract Infection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Contrave combines drugs that were used for al...</td>\n",
              "      <td>Weight Loss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"I have been on this birth control for one cyc...</td>\n",
              "      <td>Birth Control</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96145a49-0620-40db-9f2a-1430fe46da79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96145a49-0620-40db-9f2a-1430fe46da79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96145a49-0620-40db-9f2a-1430fe46da79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e10197e-1377-4737-9ba4-ae026ec75a36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e10197e-1377-4737-9ba4-ae026ec75a36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e10197e-1377-4737-9ba4-ae026ec75a36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove Null values from data\n",
        "data =data[pd.notnull(data['review'])]"
      ],
      "metadata": {
        "id": "p04kOfXZGRCI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the maxlen"
      ],
      "metadata": {
        "id": "AQUXLtLuGkbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['len'] = data['review'].apply(lambda a :len(a))"
      ],
      "metadata": {
        "id": "lU_J1cj5GjdZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['len'].plot.hist(bins=100)"
      ],
      "metadata": {
        "id": "h2CUMpIKGxBF",
        "outputId": "a378076c-8878-4a26-a71c-b7051c306ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.len.quantile(0.9)"
      ],
      "metadata": {
        "id": "wrsB3dP2G09n",
        "outputId": "1920d26f-9862-4b06-82c9-68e831714dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "758.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Y column\n",
        "we are only going to be classifying conditions for which the count of reviews are more than 3000"
      ],
      "metadata": {
        "id": "-0i2hkwmG-DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_df = data[['condition', 'review']].groupby('condition').aggregate({'review':'count'}).reset_index().sort_values('review', ascending=False)\n",
        "count_df.head()"
      ],
      "metadata": {
        "id": "zB5JcL8MG7oy",
        "outputId": "21754ca3-ea1b-4551-cfea-9e7fd72d31a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         condition  review\n",
              "175  Birth Control   38436\n",
              "273     Depression   12164\n",
              "613           Pain    8245\n",
              "133        Anxiety    7812\n",
              "87            Acne    7435"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf09c2a7-80e5-418e-b2ed-240621ef444c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Birth Control</td>\n",
              "      <td>38436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>Depression</td>\n",
              "      <td>12164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>Pain</td>\n",
              "      <td>8245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>Anxiety</td>\n",
              "      <td>7812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Acne</td>\n",
              "      <td>7435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf09c2a7-80e5-418e-b2ed-240621ef444c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf09c2a7-80e5-418e-b2ed-240621ef444c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf09c2a7-80e5-418e-b2ed-240621ef444c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-daf3f205-63bc-4b90-860e-d917e8c72c93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-daf3f205-63bc-4b90-860e-d917e8c72c93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-daf3f205-63bc-4b90-860e-d917e8c72c93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_conditions = count_df[count_df['review']>3000]['condition'].values"
      ],
      "metadata": {
        "id": "JLW3E5ymHj3E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def condition_parser(x):\n",
        "  if x in target_conditions:\n",
        "    return x\n",
        "  else:\n",
        "    return \"OTHER\"\n",
        "data['condition'] = data['condition'].apply(lambda x: condition_parser(x))"
      ],
      "metadata": {
        "id": "egXkXqFUNEz6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[data['condition']!='OTHER']\n",
        "import plotly.express as px\n"
      ],
      "metadata": {
        "id": "BLLjRt4bNiUM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.bar(count_df[count_df['review']>3000], x='condition', y='review')"
      ],
      "metadata": {
        "id": "NiQSwqsYNu2M",
        "outputId": "22ca6a94-8f94-4a5f-dda5-155c65519517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8b18d9b1-fdc2-4b8f-8f5c-788184042ff2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8b18d9b1-fdc2-4b8f-8f5c-788184042ff2\")) {                    Plotly.newPlot(                        \"8b18d9b1-fdc2-4b8f-8f5c-788184042ff2\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"condition=%{x}\\u003cbr\\u003ereview=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Birth Control\",\"Depression\",\"Pain\",\"Anxiety\",\"Acne\",\"Bipolar Disorde\",\"Insomnia\",\"Weight Loss\",\"Obesity\",\"ADHD\",\"Diabetes, Type 2\",\"Emergency Contraception\",\"High Blood Pressure\",\"Vaginal Yeast Infection\"],\"xaxis\":\"x\",\"y\":[38436,12164,8245,7812,7435,5604,4904,4857,4757,4509,3362,3290,3104,3085],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"condition\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"review\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8b18d9b1-fdc2-4b8f-8f5c-788184042ff2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(x):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, '', x)\n",
        "  return x\n",
        "\n",
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4Wq420_iOKy7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_dict = {\n",
        "    \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)\n",
        "# Usage\n",
        "replace_contractions(\"this's a text with contraction\")"
      ],
      "metadata": {
        "id": "EprPf70jSUok",
        "outputId": "b530ba40-fe19-45a4-e772-ce3de617b88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a text with contraction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lower the text\n",
        "\n",
        "data[\"review\"] = data[\"review\"].apply(lambda x:x.lower())\n",
        "\n",
        "#clean the text\n",
        "data[\"review\"] = data[\"review\"].apply(lambda x:clean_text(x))\n",
        "\n",
        "#clean numbers\n",
        "data[\"review\"] = data[\"review\"].apply(lambda x: clean_numbers(x))\n",
        "\n",
        "#clean contractions\n",
        "data[\"review\"] = data[\"review\"].apply(lambda x:replace_contractions(x))"
      ],
      "metadata": {
        "id": "fRif1PH3S73m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['condition'].unique()"
      ],
      "metadata": {
        "id": "Hg3uqcm7Ttuf",
        "outputId": "b312c974-f3ea-48c9-9560-e96a8e70cd23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Depression', 'Weight Loss', 'Birth Control',\n",
              "       'Vaginal Yeast Infection', 'Insomnia', 'Acne', 'Bipolar Disorde',\n",
              "       'Diabetes, Type 2', 'Pain', 'Emergency Contraception', 'Anxiety',\n",
              "       'ADHD', 'Obesity', 'High Blood Pressure'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split(data['review'], data['condition'], stratify=data['condition'], test_size=0.25)"
      ],
      "metadata": {
        "id": "dwqFOaqzT39D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape : \", train_X.shape)\n",
        "print(\"Test shape : \", test_X.shape)"
      ],
      "metadata": {
        "id": "uWFhDmbbUmO5",
        "outputId": "2ff53be8-92c8-4876-c7a5-7764b46ca10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape :  (83673,)\n",
            "Test shape :  (27891,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Parameters"
      ],
      "metadata": {
        "id": "1xIzaC8PWFtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "max_len = 750  # max number of words in a question to use\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5   # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "SEED=10\n",
        "debug=0"
      ],
      "metadata": {
        "id": "-NccKCE_WEyJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "##Pad the sentences\n",
        "train_X = pad_sequences(train_X, maxlen=max_len)\n",
        "test_X = pad_sequences(test_X, maxlen=max_len)"
      ],
      "metadata": {
        "id": "qREdtoTIU-bV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "train_y = le.fit_transform(train_y.values)\n",
        "test_y = le.transform(test_y.values)"
      ],
      "metadata": {
        "id": "zCoQeOsvVmM7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "id": "oGQotnqXYuG0",
        "outputId": "bae52717-e159-4444-b440-08e472a58855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADHD', 'Acne', 'Anxiety', 'Bipolar Disorde', 'Birth Control',\n",
              "       'Depression', 'Diabetes, Type 2', 'Emergency Contraception',\n",
              "       'High Blood Pressure', 'Insomnia', 'Obesity', 'Pain',\n",
              "       'Vaginal Yeast Infection', 'Weight Loss'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p7lwQEwQSAT8",
        "outputId": "c423b941-dc2b-4692-fb46-a0adeacac15a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = '/content/drive/MyDrive/Colab Notebooks/glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word.capitalize())\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "04K2JwbcSA_C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing entries in the embedding are set using np.random.normal. so we have to seed here too\n",
        "if debug:\n",
        "  embedding_matrix= np.random.randn(120000,300)\n",
        "else:\n",
        "  embedding_matrix=load_glove(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "ZByrr1w6SSBP",
        "outputId": "4f505cd8-4589-4f81-b8b7-4dd7ff37237e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning:\n",
            "\n",
            "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(embedding_matrix)"
      ],
      "metadata": {
        "id": "fjO5xWjcSoAg",
        "outputId": "f559e6c3-cb27-4a80-eb81-587b5fca81bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30940, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pytorch Model - Text CNN**"
      ],
      "metadata": {
        "id": "Af_U66U-TFYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Text(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN_Text, self).__init__()\n",
        "    filter_sizes = [1,2,3,5]\n",
        "    num_filters = 36\n",
        "    n_classes = len(le.classes_)\n",
        "    self.embedding = nn.Embedding(max_features, embed_size)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = x.unsqueeze(1)\n",
        "    x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n",
        "    x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "    x = torch.cat(x,1)\n",
        "    x = self.dropout(x)\n",
        "    logit = self.fc1(x)\n",
        "    return logit"
      ],
      "metadata": {
        "id": "LSuiEmi3TIJc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train TextCNN Model"
      ],
      "metadata": {
        "id": "oITFWe0LV7Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 6\n",
        "model = CNN_Text()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.001)\n",
        "model.cuda()\n",
        "\n",
        "# Load train and test in CUDA Memory\n",
        "x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
        "y_train = torch.tensor(train_y, dtype=torch.long).cuda()\n",
        "x_cv = torch.tensor(test_X, dtype=torch.long).cuda()\n",
        "y_cv = torch.tensor(test_y, dtype=torch.long).cuda()\n",
        "\n",
        "# Create Torch dataset\n",
        "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "# Create Data Loaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size = batch_size, shuffle=False)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  start_time = time.time()\n",
        "  # set model to train configuration\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    # predict/forward pass\n",
        "    y_pred = model(x_batch)\n",
        "    # compute loss\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    avg_loss += loss.item()/len(train_loader)\n",
        "\n",
        "    # set model to validation configuration -Doesn't get trained here\n",
        "    model.eval()\n",
        "    avg_val_loss = 0.\n",
        "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      y_pred = model(x_batch).detach()\n",
        "      avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "      # keep/store predictions\n",
        "      val_preds[i * batch_size:(i+1) * batch_size] = F.softmax(y_pred).cpu().numpy()\n",
        "\n",
        "    #check Accuracy\n",
        "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y) / len(test_y)\n",
        "    train_loss.append(avg_loss)\n",
        "    valid_loss.append(avg_val_loss)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(epoch + 1, n_epochs,\n",
        "                                                                                                     avg_loss,\n",
        "                                                                                                     avg_val_loss,\n",
        "                                                                                                     val_accuracy,\n",
        "                                                                                                     elapsed_time))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rcuVSbTSV1rW",
        "outputId": "272938ef-e287-4ff7-cef5-e4c34d0be00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-bb0a65a05fbf>:48: UserWarning:\n",
            "\n",
            "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=8.3053 \t val_loss=1240.8414  \t val_acc=0.3445  \t time=1.40s\n",
            "Epoch 1/6 \t loss=15.8787 \t val_loss=1169.0528  \t val_acc=0.3445  \t time=2.76s\n",
            "Epoch 1/6 \t loss=22.8895 \t val_loss=1138.2676  \t val_acc=0.3445  \t time=4.11s\n",
            "Epoch 1/6 \t loss=29.9528 \t val_loss=1139.8824  \t val_acc=0.3445  \t time=5.46s\n",
            "Epoch 1/6 \t loss=36.5940 \t val_loss=1144.9334  \t val_acc=0.3445  \t time=6.80s\n",
            "Epoch 1/6 \t loss=43.4874 \t val_loss=1133.6441  \t val_acc=0.3445  \t time=8.15s\n",
            "Epoch 1/6 \t loss=50.4523 \t val_loss=1109.9678  \t val_acc=0.3445  \t time=9.50s\n",
            "Epoch 1/6 \t loss=57.4561 \t val_loss=1083.1391  \t val_acc=0.3445  \t time=10.85s\n",
            "Epoch 1/6 \t loss=64.0581 \t val_loss=1062.2063  \t val_acc=0.3445  \t time=12.20s\n",
            "Epoch 1/6 \t loss=70.5487 \t val_loss=1048.3175  \t val_acc=0.3459  \t time=13.55s\n",
            "Epoch 1/6 \t loss=77.1125 \t val_loss=1036.8585  \t val_acc=0.3554  \t time=15.15s\n",
            "Epoch 1/6 \t loss=83.6975 \t val_loss=1024.7140  \t val_acc=0.3684  \t time=16.51s\n",
            "Epoch 1/6 \t loss=89.9737 \t val_loss=1010.1749  \t val_acc=0.3841  \t time=17.86s\n",
            "Epoch 1/6 \t loss=96.4049 \t val_loss=994.3593  \t val_acc=0.3917  \t time=19.21s\n",
            "Epoch 1/6 \t loss=102.3734 \t val_loss=976.0161  \t val_acc=0.3903  \t time=20.56s\n",
            "Epoch 1/6 \t loss=108.5094 \t val_loss=956.9440  \t val_acc=0.3864  \t time=21.91s\n",
            "Epoch 1/6 \t loss=114.2957 \t val_loss=938.5075  \t val_acc=0.3856  \t time=23.26s\n",
            "Epoch 1/6 \t loss=120.0024 \t val_loss=920.5346  \t val_acc=0.3869  \t time=24.61s\n",
            "Epoch 1/6 \t loss=125.7808 \t val_loss=903.2736  \t val_acc=0.3925  \t time=25.96s\n",
            "Epoch 1/6 \t loss=131.1848 \t val_loss=886.6483  \t val_acc=0.3996  \t time=27.31s\n",
            "Epoch 1/6 \t loss=136.6054 \t val_loss=869.9813  \t val_acc=0.4126  \t time=28.66s\n",
            "Epoch 1/6 \t loss=142.0665 \t val_loss=853.0302  \t val_acc=0.4284  \t time=30.01s\n",
            "Epoch 1/6 \t loss=147.5394 \t val_loss=835.8610  \t val_acc=0.4458  \t time=31.36s\n",
            "Epoch 1/6 \t loss=152.5144 \t val_loss=818.6797  \t val_acc=0.4681  \t time=32.72s\n",
            "Epoch 1/6 \t loss=157.3389 \t val_loss=801.9506  \t val_acc=0.4957  \t time=34.07s\n",
            "Epoch 1/6 \t loss=162.2496 \t val_loss=786.0453  \t val_acc=0.5262  \t time=35.42s\n",
            "Epoch 1/6 \t loss=167.1651 \t val_loss=771.2456  \t val_acc=0.5574  \t time=36.77s\n",
            "Epoch 1/6 \t loss=171.8630 \t val_loss=756.8703  \t val_acc=0.5719  \t time=38.12s\n",
            "Epoch 1/6 \t loss=176.5970 \t val_loss=742.2677  \t val_acc=0.5802  \t time=39.47s\n",
            "Epoch 1/6 \t loss=181.2974 \t val_loss=727.3494  \t val_acc=0.5854  \t time=41.09s\n",
            "Epoch 1/6 \t loss=185.9546 \t val_loss=712.0022  \t val_acc=0.5851  \t time=42.44s\n",
            "Epoch 1/6 \t loss=190.1832 \t val_loss=697.1086  \t val_acc=0.5848  \t time=43.79s\n",
            "Epoch 1/6 \t loss=194.5166 \t val_loss=682.7917  \t val_acc=0.5855  \t time=45.14s\n",
            "Epoch 1/6 \t loss=198.6519 \t val_loss=669.3135  \t val_acc=0.5893  \t time=46.49s\n",
            "Epoch 1/6 \t loss=202.5695 \t val_loss=656.6551  \t val_acc=0.5936  \t time=47.84s\n",
            "Epoch 1/6 \t loss=206.6723 \t val_loss=644.5832  \t val_acc=0.5979  \t time=49.19s\n",
            "Epoch 1/6 \t loss=210.6024 \t val_loss=632.8121  \t val_acc=0.6039  \t time=50.54s\n",
            "Epoch 1/6 \t loss=214.7530 \t val_loss=621.0618  \t val_acc=0.6103  \t time=51.89s\n",
            "Epoch 1/6 \t loss=218.5419 \t val_loss=609.3251  \t val_acc=0.6172  \t time=53.24s\n",
            "Epoch 1/6 \t loss=222.2726 \t val_loss=597.3568  \t val_acc=0.6247  \t time=54.59s\n",
            "Epoch 1/6 \t loss=225.9279 \t val_loss=585.6021  \t val_acc=0.6325  \t time=55.94s\n",
            "Epoch 1/6 \t loss=229.5054 \t val_loss=573.8703  \t val_acc=0.6410  \t time=57.30s\n",
            "Epoch 1/6 \t loss=233.0047 \t val_loss=562.7678  \t val_acc=0.6472  \t time=58.65s\n",
            "Epoch 1/6 \t loss=236.5882 \t val_loss=552.3391  \t val_acc=0.6542  \t time=60.00s\n",
            "Epoch 1/6 \t loss=239.8828 \t val_loss=542.4619  \t val_acc=0.6602  \t time=61.35s\n",
            "Epoch 1/6 \t loss=243.3135 \t val_loss=533.0319  \t val_acc=0.6683  \t time=62.71s\n",
            "Epoch 1/6 \t loss=246.5748 \t val_loss=523.6759  \t val_acc=0.6793  \t time=64.06s\n",
            "Epoch 1/6 \t loss=249.7595 \t val_loss=514.8300  \t val_acc=0.6872  \t time=65.66s\n",
            "Epoch 1/6 \t loss=252.9816 \t val_loss=506.2876  \t val_acc=0.6956  \t time=67.01s\n",
            "Epoch 1/6 \t loss=256.1953 \t val_loss=497.5630  \t val_acc=0.7079  \t time=68.36s\n",
            "Epoch 1/6 \t loss=259.0469 \t val_loss=489.0047  \t val_acc=0.7174  \t time=69.71s\n",
            "Epoch 1/6 \t loss=262.0408 \t val_loss=480.7698  \t val_acc=0.7245  \t time=71.07s\n",
            "Epoch 1/6 \t loss=265.1406 \t val_loss=472.5342  \t val_acc=0.7324  \t time=72.43s\n",
            "Epoch 1/6 \t loss=268.0009 \t val_loss=464.8095  \t val_acc=0.7334  \t time=73.78s\n",
            "Epoch 1/6 \t loss=270.9852 \t val_loss=457.5897  \t val_acc=0.7303  \t time=75.13s\n",
            "Epoch 1/6 \t loss=273.9928 \t val_loss=451.7071  \t val_acc=0.7277  \t time=76.48s\n",
            "Epoch 1/6 \t loss=276.7429 \t val_loss=445.9856  \t val_acc=0.7293  \t time=77.83s\n",
            "Epoch 1/6 \t loss=279.3997 \t val_loss=439.8024  \t val_acc=0.7353  \t time=79.18s\n",
            "Epoch 1/6 \t loss=282.1004 \t val_loss=432.7507  \t val_acc=0.7459  \t time=80.53s\n",
            "Epoch 1/6 \t loss=284.7376 \t val_loss=426.3229  \t val_acc=0.7561  \t time=81.88s\n",
            "Epoch 1/6 \t loss=287.2344 \t val_loss=420.5856  \t val_acc=0.7620  \t time=83.23s\n",
            "Epoch 1/6 \t loss=289.7630 \t val_loss=415.2820  \t val_acc=0.7637  \t time=84.58s\n",
            "Epoch 1/6 \t loss=292.2445 \t val_loss=410.7961  \t val_acc=0.7644  \t time=85.93s\n",
            "Epoch 1/6 \t loss=295.0305 \t val_loss=405.7100  \t val_acc=0.7677  \t time=87.28s\n",
            "Epoch 1/6 \t loss=297.4207 \t val_loss=399.6867  \t val_acc=0.7711  \t time=88.63s\n",
            "Epoch 1/6 \t loss=299.9530 \t val_loss=394.2077  \t val_acc=0.7733  \t time=89.98s\n",
            "Epoch 1/6 \t loss=302.3217 \t val_loss=389.5630  \t val_acc=0.7741  \t time=91.58s\n",
            "Epoch 1/6 \t loss=304.8387 \t val_loss=385.6792  \t val_acc=0.7721  \t time=92.93s\n",
            "Epoch 1/6 \t loss=307.3598 \t val_loss=381.9194  \t val_acc=0.7733  \t time=94.28s\n",
            "Epoch 1/6 \t loss=309.6108 \t val_loss=377.8038  \t val_acc=0.7737  \t time=95.63s\n",
            "Epoch 1/6 \t loss=311.8479 \t val_loss=373.8388  \t val_acc=0.7736  \t time=96.98s\n",
            "Epoch 1/6 \t loss=314.1560 \t val_loss=370.0887  \t val_acc=0.7754  \t time=98.33s\n",
            "Epoch 1/6 \t loss=316.7405 \t val_loss=366.1887  \t val_acc=0.7795  \t time=99.68s\n",
            "Epoch 1/6 \t loss=319.0134 \t val_loss=362.2469  \t val_acc=0.7842  \t time=101.03s\n",
            "Epoch 1/6 \t loss=321.2606 \t val_loss=358.5647  \t val_acc=0.7927  \t time=102.38s\n",
            "Epoch 1/6 \t loss=323.5167 \t val_loss=355.3617  \t val_acc=0.7979  \t time=103.73s\n",
            "Epoch 1/6 \t loss=325.7733 \t val_loss=352.4741  \t val_acc=0.8004  \t time=105.08s\n",
            "Epoch 1/6 \t loss=327.8560 \t val_loss=349.3484  \t val_acc=0.8024  \t time=106.43s\n",
            "Epoch 1/6 \t loss=330.1399 \t val_loss=346.1217  \t val_acc=0.8030  \t time=107.78s\n",
            "Epoch 1/6 \t loss=332.2382 \t val_loss=342.5414  \t val_acc=0.8031  \t time=109.13s\n",
            "Epoch 1/6 \t loss=334.1372 \t val_loss=339.0086  \t val_acc=0.8037  \t time=110.48s\n",
            "Epoch 1/6 \t loss=336.0556 \t val_loss=335.5897  \t val_acc=0.8032  \t time=111.83s\n",
            "Epoch 1/6 \t loss=338.1795 \t val_loss=333.1002  \t val_acc=0.8017  \t time=113.18s\n",
            "Epoch 1/6 \t loss=340.1380 \t val_loss=330.8734  \t val_acc=0.8003  \t time=114.53s\n",
            "Epoch 1/6 \t loss=342.1567 \t val_loss=328.5813  \t val_acc=0.8013  \t time=115.88s\n",
            "Epoch 1/6 \t loss=344.0642 \t val_loss=326.3978  \t val_acc=0.8023  \t time=117.49s\n",
            "Epoch 1/6 \t loss=345.9886 \t val_loss=324.0107  \t val_acc=0.8041  \t time=118.84s\n",
            "Epoch 1/6 \t loss=347.9122 \t val_loss=321.6222  \t val_acc=0.8065  \t time=120.19s\n",
            "Epoch 1/6 \t loss=349.7736 \t val_loss=319.5359  \t val_acc=0.8086  \t time=121.54s\n",
            "Epoch 1/6 \t loss=351.7073 \t val_loss=317.5731  \t val_acc=0.8087  \t time=122.89s\n",
            "Epoch 1/6 \t loss=353.5479 \t val_loss=315.6077  \t val_acc=0.8102  \t time=124.24s\n",
            "Epoch 1/6 \t loss=355.5550 \t val_loss=313.7136  \t val_acc=0.8099  \t time=125.59s\n",
            "Epoch 1/6 \t loss=357.4163 \t val_loss=311.8010  \t val_acc=0.8094  \t time=126.94s\n",
            "Epoch 1/6 \t loss=359.4554 \t val_loss=310.2272  \t val_acc=0.8102  \t time=128.29s\n",
            "Epoch 1/6 \t loss=361.2328 \t val_loss=308.4955  \t val_acc=0.8110  \t time=129.64s\n",
            "Epoch 1/6 \t loss=363.0904 \t val_loss=306.9661  \t val_acc=0.8110  \t time=130.99s\n",
            "Epoch 1/6 \t loss=365.0567 \t val_loss=306.1768  \t val_acc=0.8141  \t time=132.34s\n",
            "Epoch 1/6 \t loss=366.9532 \t val_loss=304.7865  \t val_acc=0.8150  \t time=133.69s\n",
            "Epoch 1/6 \t loss=368.9009 \t val_loss=303.0362  \t val_acc=0.8166  \t time=135.04s\n",
            "Epoch 1/6 \t loss=370.6980 \t val_loss=300.6444  \t val_acc=0.8165  \t time=136.39s\n",
            "Epoch 1/6 \t loss=372.5085 \t val_loss=298.6414  \t val_acc=0.8178  \t time=137.74s\n",
            "Epoch 1/6 \t loss=374.4197 \t val_loss=296.9362  \t val_acc=0.8184  \t time=139.09s\n",
            "Epoch 1/6 \t loss=376.2226 \t val_loss=295.2067  \t val_acc=0.8186  \t time=140.44s\n",
            "Epoch 1/6 \t loss=378.1244 \t val_loss=293.8250  \t val_acc=0.8180  \t time=141.79s\n",
            "Epoch 1/6 \t loss=380.1163 \t val_loss=292.6571  \t val_acc=0.8184  \t time=143.40s\n",
            "Epoch 1/6 \t loss=381.9769 \t val_loss=291.9076  \t val_acc=0.8193  \t time=144.75s\n",
            "Epoch 1/6 \t loss=383.6591 \t val_loss=291.4035  \t val_acc=0.8194  \t time=146.10s\n",
            "Epoch 1/6 \t loss=385.6332 \t val_loss=290.6952  \t val_acc=0.8199  \t time=147.45s\n",
            "Epoch 1/6 \t loss=387.2526 \t val_loss=289.3183  \t val_acc=0.8192  \t time=148.80s\n",
            "Epoch 1/6 \t loss=389.0437 \t val_loss=287.9032  \t val_acc=0.8198  \t time=150.14s\n",
            "Epoch 1/6 \t loss=390.5718 \t val_loss=286.3265  \t val_acc=0.8206  \t time=151.50s\n",
            "Epoch 1/6 \t loss=392.3618 \t val_loss=284.1196  \t val_acc=0.8217  \t time=152.85s\n",
            "Epoch 1/6 \t loss=393.9848 \t val_loss=281.8936  \t val_acc=0.8222  \t time=154.20s\n",
            "Epoch 1/6 \t loss=395.7095 \t val_loss=280.1759  \t val_acc=0.8236  \t time=155.55s\n",
            "Epoch 1/6 \t loss=397.3966 \t val_loss=279.0707  \t val_acc=0.8247  \t time=156.90s\n",
            "Epoch 1/6 \t loss=399.1654 \t val_loss=278.2517  \t val_acc=0.8249  \t time=158.25s\n",
            "Epoch 1/6 \t loss=401.1411 \t val_loss=277.4624  \t val_acc=0.8261  \t time=159.60s\n",
            "Epoch 1/6 \t loss=402.9173 \t val_loss=276.7496  \t val_acc=0.8267  \t time=160.95s\n",
            "Epoch 1/6 \t loss=404.6539 \t val_loss=276.5447  \t val_acc=0.8261  \t time=162.30s\n",
            "Epoch 1/6 \t loss=406.0853 \t val_loss=275.5923  \t val_acc=0.8276  \t time=163.65s\n",
            "Epoch 1/6 \t loss=407.7032 \t val_loss=274.2529  \t val_acc=0.8284  \t time=165.00s\n",
            "Epoch 1/6 \t loss=409.3168 \t val_loss=272.8134  \t val_acc=0.8297  \t time=166.35s\n",
            "Epoch 1/6 \t loss=411.2064 \t val_loss=271.5944  \t val_acc=0.8290  \t time=167.96s\n",
            "Epoch 1/6 \t loss=412.8981 \t val_loss=271.5241  \t val_acc=0.8289  \t time=169.31s\n",
            "Epoch 1/6 \t loss=414.5109 \t val_loss=271.0983  \t val_acc=0.8282  \t time=170.66s\n",
            "Epoch 1/6 \t loss=416.0472 \t val_loss=270.5028  \t val_acc=0.8281  \t time=172.01s\n",
            "Epoch 1/6 \t loss=417.7480 \t val_loss=269.8916  \t val_acc=0.8288  \t time=173.36s\n",
            "Epoch 1/6 \t loss=419.4107 \t val_loss=269.0912  \t val_acc=0.8294  \t time=174.70s\n",
            "Epoch 1/6 \t loss=420.9894 \t val_loss=267.7023  \t val_acc=0.8297  \t time=176.06s\n",
            "Epoch 1/6 \t loss=422.6209 \t val_loss=266.3567  \t val_acc=0.8298  \t time=177.40s\n",
            "Epoch 1/6 \t loss=424.2244 \t val_loss=265.5615  \t val_acc=0.8297  \t time=178.75s\n",
            "Epoch 1/6 \t loss=425.8710 \t val_loss=265.4570  \t val_acc=0.8292  \t time=180.10s\n",
            "Epoch 1/6 \t loss=427.5989 \t val_loss=265.4946  \t val_acc=0.8286  \t time=181.45s\n",
            "Epoch 1/6 \t loss=429.1648 \t val_loss=265.2644  \t val_acc=0.8278  \t time=182.80s\n",
            "Epoch 1/6 \t loss=430.6957 \t val_loss=264.0517  \t val_acc=0.8294  \t time=184.15s\n",
            "Epoch 1/6 \t loss=432.3188 \t val_loss=262.9254  \t val_acc=0.8294  \t time=185.50s\n",
            "Epoch 1/6 \t loss=433.8837 \t val_loss=262.1456  \t val_acc=0.8301  \t time=186.85s\n",
            "Epoch 1/6 \t loss=435.6139 \t val_loss=261.5157  \t val_acc=0.8316  \t time=188.20s\n",
            "Epoch 1/6 \t loss=437.3132 \t val_loss=260.2504  \t val_acc=0.8322  \t time=189.55s\n",
            "Epoch 1/6 \t loss=438.8371 \t val_loss=259.2528  \t val_acc=0.8334  \t time=190.90s\n",
            "Epoch 1/6 \t loss=440.3073 \t val_loss=258.3942  \t val_acc=0.8345  \t time=192.25s\n",
            "Epoch 1/6 \t loss=441.6884 \t val_loss=257.8076  \t val_acc=0.8347  \t time=193.87s\n",
            "Epoch 1/6 \t loss=443.3919 \t val_loss=257.6199  \t val_acc=0.8343  \t time=195.22s\n",
            "Epoch 1/6 \t loss=444.8782 \t val_loss=257.4955  \t val_acc=0.8344  \t time=196.57s\n",
            "Epoch 1/6 \t loss=446.5721 \t val_loss=257.7064  \t val_acc=0.8346  \t time=197.92s\n",
            "Epoch 1/6 \t loss=448.2417 \t val_loss=257.6745  \t val_acc=0.8341  \t time=199.27s\n",
            "Epoch 1/6 \t loss=449.7789 \t val_loss=256.4235  \t val_acc=0.8347  \t time=200.61s\n",
            "Epoch 1/6 \t loss=451.3097 \t val_loss=255.2647  \t val_acc=0.8353  \t time=201.96s\n",
            "Epoch 1/6 \t loss=452.7887 \t val_loss=254.5184  \t val_acc=0.8353  \t time=203.31s\n",
            "Epoch 1/6 \t loss=454.3732 \t val_loss=254.0352  \t val_acc=0.8356  \t time=204.66s\n",
            "Epoch 1/6 \t loss=455.8586 \t val_loss=254.0144  \t val_acc=0.8350  \t time=206.01s\n",
            "Epoch 1/6 \t loss=457.2679 \t val_loss=254.0680  \t val_acc=0.8341  \t time=207.36s\n",
            "Epoch 1/6 \t loss=459.1496 \t val_loss=253.4404  \t val_acc=0.8342  \t time=208.71s\n",
            "Epoch 1/6 \t loss=460.6196 \t val_loss=252.3154  \t val_acc=0.8356  \t time=210.07s\n",
            "Epoch 1/6 \t loss=462.2503 \t val_loss=251.1426  \t val_acc=0.8372  \t time=211.43s\n",
            "Epoch 1/6 \t loss=463.7614 \t val_loss=250.2330  \t val_acc=0.8382  \t time=212.78s\n",
            "Epoch 1/6 \t loss=465.2418 \t val_loss=249.3681  \t val_acc=0.8389  \t time=214.12s\n",
            "Epoch 1/6 \t loss=466.5679 \t val_loss=248.8253  \t val_acc=0.8395  \t time=215.47s\n",
            "Epoch 1/6 \t loss=468.1576 \t val_loss=248.3153  \t val_acc=0.8400  \t time=216.82s\n",
            "Epoch 1/6 \t loss=469.7316 \t val_loss=248.0393  \t val_acc=0.8405  \t time=218.17s\n",
            "Epoch 1/6 \t loss=471.2443 \t val_loss=247.8386  \t val_acc=0.8403  \t time=219.77s\n",
            "Epoch 1/6 \t loss=472.8097 \t val_loss=248.0049  \t val_acc=0.8395  \t time=221.12s\n",
            "Epoch 1/6 \t loss=474.1349 \t val_loss=247.9298  \t val_acc=0.8391  \t time=222.47s\n",
            "Epoch 1/6 \t loss=474.7297 \t val_loss=248.0334  \t val_acc=0.8386  \t time=223.80s\n",
            "Epoch 2/6 \t loss=1.5464 \t val_loss=247.4770  \t val_acc=0.8383  \t time=1.35s\n",
            "Epoch 2/6 \t loss=3.0664 \t val_loss=246.6515  \t val_acc=0.8394  \t time=2.70s\n",
            "Epoch 2/6 \t loss=4.4886 \t val_loss=245.7852  \t val_acc=0.8405  \t time=4.04s\n",
            "Epoch 2/6 \t loss=5.9558 \t val_loss=244.8250  \t val_acc=0.8411  \t time=5.39s\n",
            "Epoch 2/6 \t loss=7.4219 \t val_loss=244.1936  \t val_acc=0.8421  \t time=6.74s\n",
            "Epoch 2/6 \t loss=8.9423 \t val_loss=244.0220  \t val_acc=0.8424  \t time=8.09s\n",
            "Epoch 2/6 \t loss=10.3725 \t val_loss=244.4069  \t val_acc=0.8412  \t time=9.44s\n",
            "Epoch 2/6 \t loss=11.9236 \t val_loss=244.3297  \t val_acc=0.8408  \t time=10.79s\n",
            "Epoch 2/6 \t loss=13.2926 \t val_loss=243.4991  \t val_acc=0.8416  \t time=12.14s\n",
            "Epoch 2/6 \t loss=14.7778 \t val_loss=242.6909  \t val_acc=0.8427  \t time=13.49s\n",
            "Epoch 2/6 \t loss=16.1045 \t val_loss=241.9087  \t val_acc=0.8432  \t time=14.83s\n",
            "Epoch 2/6 \t loss=17.6143 \t val_loss=241.8396  \t val_acc=0.8427  \t time=16.18s\n",
            "Epoch 2/6 \t loss=18.8751 \t val_loss=242.4637  \t val_acc=0.8421  \t time=17.54s\n",
            "Epoch 2/6 \t loss=20.0432 \t val_loss=243.0424  \t val_acc=0.8417  \t time=18.89s\n",
            "Epoch 2/6 \t loss=21.3879 \t val_loss=243.9636  \t val_acc=0.8405  \t time=20.49s\n",
            "Epoch 2/6 \t loss=22.8262 \t val_loss=244.4447  \t val_acc=0.8401  \t time=21.84s\n",
            "Epoch 2/6 \t loss=24.3786 \t val_loss=243.8438  \t val_acc=0.8406  \t time=23.20s\n",
            "Epoch 2/6 \t loss=25.7110 \t val_loss=242.6155  \t val_acc=0.8408  \t time=24.55s\n",
            "Epoch 2/6 \t loss=27.3320 \t val_loss=241.3375  \t val_acc=0.8414  \t time=25.90s\n",
            "Epoch 2/6 \t loss=28.7401 \t val_loss=240.1897  \t val_acc=0.8423  \t time=27.25s\n",
            "Epoch 2/6 \t loss=30.1540 \t val_loss=239.5175  \t val_acc=0.8436  \t time=28.60s\n",
            "Epoch 2/6 \t loss=31.5378 \t val_loss=239.2319  \t val_acc=0.8435  \t time=29.95s\n",
            "Epoch 2/6 \t loss=33.0824 \t val_loss=239.5485  \t val_acc=0.8420  \t time=31.30s\n",
            "Epoch 2/6 \t loss=34.5157 \t val_loss=239.2740  \t val_acc=0.8425  \t time=32.65s\n",
            "Epoch 2/6 \t loss=35.7670 \t val_loss=239.0047  \t val_acc=0.8421  \t time=34.00s\n",
            "Epoch 2/6 \t loss=37.2926 \t val_loss=238.4375  \t val_acc=0.8434  \t time=35.35s\n",
            "Epoch 2/6 \t loss=38.7792 \t val_loss=237.3039  \t val_acc=0.8446  \t time=36.70s\n",
            "Epoch 2/6 \t loss=40.2129 \t val_loss=236.2040  \t val_acc=0.8457  \t time=38.05s\n",
            "Epoch 2/6 \t loss=41.5529 \t val_loss=235.9281  \t val_acc=0.8455  \t time=39.40s\n",
            "Epoch 2/6 \t loss=42.8806 \t val_loss=236.4353  \t val_acc=0.8438  \t time=40.75s\n",
            "Epoch 2/6 \t loss=44.1643 \t val_loss=237.0761  \t val_acc=0.8428  \t time=42.10s\n",
            "Epoch 2/6 \t loss=45.6139 \t val_loss=236.5797  \t val_acc=0.8426  \t time=43.45s\n",
            "Epoch 2/6 \t loss=47.0937 \t val_loss=235.6596  \t val_acc=0.8438  \t time=45.05s\n",
            "Epoch 2/6 \t loss=48.4843 \t val_loss=234.9347  \t val_acc=0.8443  \t time=46.40s\n",
            "Epoch 2/6 \t loss=49.9199 \t val_loss=234.9227  \t val_acc=0.8448  \t time=47.76s\n",
            "Epoch 2/6 \t loss=51.1011 \t val_loss=236.1276  \t val_acc=0.8440  \t time=49.11s\n",
            "Epoch 2/6 \t loss=52.5432 \t val_loss=237.9026  \t val_acc=0.8424  \t time=50.46s\n",
            "Epoch 2/6 \t loss=53.9749 \t val_loss=238.4280  \t val_acc=0.8422  \t time=51.81s\n",
            "Epoch 2/6 \t loss=55.3456 \t val_loss=237.9752  \t val_acc=0.8412  \t time=53.16s\n",
            "Epoch 2/6 \t loss=56.5944 \t val_loss=236.2541  \t val_acc=0.8421  \t time=54.51s\n",
            "Epoch 2/6 \t loss=58.0879 \t val_loss=234.6387  \t val_acc=0.8422  \t time=55.86s\n",
            "Epoch 2/6 \t loss=59.5395 \t val_loss=234.1803  \t val_acc=0.8427  \t time=57.21s\n",
            "Epoch 2/6 \t loss=60.8840 \t val_loss=234.6744  \t val_acc=0.8421  \t time=58.56s\n",
            "Epoch 2/6 \t loss=62.1820 \t val_loss=235.0859  \t val_acc=0.8419  \t time=59.90s\n",
            "Epoch 2/6 \t loss=63.6558 \t val_loss=234.6824  \t val_acc=0.8424  \t time=61.25s\n",
            "Epoch 2/6 \t loss=65.1022 \t val_loss=233.2112  \t val_acc=0.8443  \t time=62.60s\n",
            "Epoch 2/6 \t loss=66.5990 \t val_loss=231.3528  \t val_acc=0.8451  \t time=63.95s\n",
            "Epoch 2/6 \t loss=67.8483 \t val_loss=230.9761  \t val_acc=0.8455  \t time=65.31s\n",
            "Epoch 2/6 \t loss=69.2537 \t val_loss=230.4182  \t val_acc=0.8467  \t time=66.66s\n",
            "Epoch 2/6 \t loss=70.7387 \t val_loss=229.8072  \t val_acc=0.8477  \t time=68.01s\n",
            "Epoch 2/6 \t loss=72.1602 \t val_loss=229.4228  \t val_acc=0.8481  \t time=69.36s\n",
            "Epoch 2/6 \t loss=73.3077 \t val_loss=228.9710  \t val_acc=0.8487  \t time=70.96s\n",
            "Epoch 2/6 \t loss=74.7015 \t val_loss=228.7183  \t val_acc=0.8492  \t time=72.31s\n",
            "Epoch 2/6 \t loss=76.0511 \t val_loss=228.6568  \t val_acc=0.8487  \t time=73.66s\n",
            "Epoch 2/6 \t loss=77.7015 \t val_loss=228.4956  \t val_acc=0.8484  \t time=75.01s\n",
            "Epoch 2/6 \t loss=79.0340 \t val_loss=228.2083  \t val_acc=0.8486  \t time=76.36s\n",
            "Epoch 2/6 \t loss=80.3534 \t val_loss=228.0011  \t val_acc=0.8492  \t time=77.72s\n",
            "Epoch 2/6 \t loss=81.5738 \t val_loss=228.1465  \t val_acc=0.8485  \t time=79.07s\n",
            "Epoch 2/6 \t loss=82.8395 \t val_loss=228.9552  \t val_acc=0.8478  \t time=80.41s\n",
            "Epoch 2/6 \t loss=84.2569 \t val_loss=228.9802  \t val_acc=0.8477  \t time=81.76s\n",
            "Epoch 2/6 \t loss=85.5019 \t val_loss=228.8515  \t val_acc=0.8467  \t time=83.11s\n",
            "Epoch 2/6 \t loss=86.7789 \t val_loss=228.6656  \t val_acc=0.8469  \t time=84.46s\n",
            "Epoch 2/6 \t loss=88.0169 \t val_loss=228.3771  \t val_acc=0.8467  \t time=85.82s\n",
            "Epoch 2/6 \t loss=89.5051 \t val_loss=227.9237  \t val_acc=0.8464  \t time=87.16s\n",
            "Epoch 2/6 \t loss=90.9953 \t val_loss=227.4278  \t val_acc=0.8467  \t time=88.51s\n",
            "Epoch 2/6 \t loss=92.3328 \t val_loss=226.9005  \t val_acc=0.8480  \t time=89.86s\n",
            "Epoch 2/6 \t loss=93.4962 \t val_loss=226.7277  \t val_acc=0.8482  \t time=91.21s\n",
            "Epoch 2/6 \t loss=94.7271 \t val_loss=226.7841  \t val_acc=0.8473  \t time=92.56s\n",
            "Epoch 2/6 \t loss=96.1176 \t val_loss=226.8284  \t val_acc=0.8469  \t time=93.91s\n",
            "Epoch 2/6 \t loss=97.5309 \t val_loss=226.6258  \t val_acc=0.8471  \t time=95.27s\n",
            "Epoch 2/6 \t loss=98.8720 \t val_loss=225.9225  \t val_acc=0.8482  \t time=96.87s\n",
            "Epoch 2/6 \t loss=100.1925 \t val_loss=225.1040  \t val_acc=0.8491  \t time=98.22s\n",
            "Epoch 2/6 \t loss=101.3134 \t val_loss=224.4968  \t val_acc=0.8491  \t time=99.57s\n",
            "Epoch 2/6 \t loss=102.5864 \t val_loss=224.3722  \t val_acc=0.8495  \t time=100.92s\n",
            "Epoch 2/6 \t loss=103.8883 \t val_loss=224.1771  \t val_acc=0.8495  \t time=102.27s\n",
            "Epoch 2/6 \t loss=105.2734 \t val_loss=224.2375  \t val_acc=0.8503  \t time=103.62s\n",
            "Epoch 2/6 \t loss=106.5312 \t val_loss=224.4656  \t val_acc=0.8491  \t time=104.97s\n",
            "Epoch 2/6 \t loss=108.0265 \t val_loss=224.6194  \t val_acc=0.8498  \t time=106.32s\n",
            "Epoch 2/6 \t loss=109.4908 \t val_loss=224.6837  \t val_acc=0.8503  \t time=107.68s\n",
            "Epoch 2/6 \t loss=110.9224 \t val_loss=224.5390  \t val_acc=0.8507  \t time=109.02s\n",
            "Epoch 2/6 \t loss=112.0651 \t val_loss=224.4321  \t val_acc=0.8512  \t time=110.38s\n",
            "Epoch 2/6 \t loss=113.2299 \t val_loss=224.0288  \t val_acc=0.8494  \t time=111.72s\n",
            "Epoch 2/6 \t loss=114.7621 \t val_loss=223.1164  \t val_acc=0.8495  \t time=113.07s\n",
            "Epoch 2/6 \t loss=116.1364 \t val_loss=222.2851  \t val_acc=0.8504  \t time=114.42s\n",
            "Epoch 2/6 \t loss=117.4489 \t val_loss=221.7039  \t val_acc=0.8515  \t time=115.77s\n",
            "Epoch 2/6 \t loss=118.6839 \t val_loss=221.6803  \t val_acc=0.8516  \t time=117.13s\n",
            "Epoch 2/6 \t loss=119.8068 \t val_loss=222.6285  \t val_acc=0.8502  \t time=118.48s\n",
            "Epoch 2/6 \t loss=121.4226 \t val_loss=224.1557  \t val_acc=0.8484  \t time=119.83s\n",
            "Epoch 2/6 \t loss=122.8185 \t val_loss=225.2120  \t val_acc=0.8478  \t time=121.18s\n",
            "Epoch 2/6 \t loss=124.2404 \t val_loss=224.2096  \t val_acc=0.8490  \t time=122.79s\n",
            "Epoch 2/6 \t loss=125.4388 \t val_loss=222.7296  \t val_acc=0.8507  \t time=124.14s\n",
            "Epoch 2/6 \t loss=126.5300 \t val_loss=221.3410  \t val_acc=0.8532  \t time=125.49s\n",
            "Epoch 2/6 \t loss=127.8912 \t val_loss=220.2840  \t val_acc=0.8536  \t time=126.84s\n",
            "Epoch 2/6 \t loss=129.0542 \t val_loss=220.0289  \t val_acc=0.8527  \t time=128.19s\n",
            "Epoch 2/6 \t loss=130.4095 \t val_loss=220.1859  \t val_acc=0.8516  \t time=129.54s\n",
            "Epoch 2/6 \t loss=131.7836 \t val_loss=220.6089  \t val_acc=0.8497  \t time=130.89s\n",
            "Epoch 2/6 \t loss=133.1483 \t val_loss=220.8806  \t val_acc=0.8490  \t time=132.24s\n",
            "Epoch 2/6 \t loss=134.2648 \t val_loss=221.1900  \t val_acc=0.8496  \t time=133.59s\n",
            "Epoch 2/6 \t loss=135.4877 \t val_loss=221.3282  \t val_acc=0.8502  \t time=134.93s\n",
            "Epoch 2/6 \t loss=136.9946 \t val_loss=220.9948  \t val_acc=0.8516  \t time=136.28s\n",
            "Epoch 2/6 \t loss=138.3776 \t val_loss=219.9965  \t val_acc=0.8519  \t time=137.63s\n",
            "Epoch 2/6 \t loss=139.7110 \t val_loss=219.3019  \t val_acc=0.8524  \t time=138.98s\n",
            "Epoch 2/6 \t loss=141.1609 \t val_loss=218.9047  \t val_acc=0.8526  \t time=140.33s\n",
            "Epoch 2/6 \t loss=142.4081 \t val_loss=218.9431  \t val_acc=0.8533  \t time=141.68s\n",
            "Epoch 2/6 \t loss=143.8403 \t val_loss=219.5075  \t val_acc=0.8530  \t time=143.03s\n",
            "Epoch 2/6 \t loss=145.0335 \t val_loss=220.2690  \t val_acc=0.8519  \t time=144.38s\n",
            "Epoch 2/6 \t loss=146.4059 \t val_loss=220.7092  \t val_acc=0.8513  \t time=145.73s\n",
            "Epoch 2/6 \t loss=147.6377 \t val_loss=220.2138  \t val_acc=0.8523  \t time=147.34s\n",
            "Epoch 2/6 \t loss=148.9227 \t val_loss=219.4358  \t val_acc=0.8535  \t time=148.69s\n",
            "Epoch 2/6 \t loss=150.4244 \t val_loss=218.8846  \t val_acc=0.8539  \t time=150.04s\n",
            "Epoch 2/6 \t loss=151.9047 \t val_loss=218.9167  \t val_acc=0.8517  \t time=151.39s\n",
            "Epoch 2/6 \t loss=153.2429 \t val_loss=219.2149  \t val_acc=0.8513  \t time=152.74s\n",
            "Epoch 2/6 \t loss=154.5768 \t val_loss=218.9615  \t val_acc=0.8510  \t time=154.09s\n",
            "Epoch 2/6 \t loss=155.8810 \t val_loss=218.4311  \t val_acc=0.8519  \t time=155.44s\n",
            "Epoch 2/6 \t loss=157.2404 \t val_loss=217.7825  \t val_acc=0.8521  \t time=156.78s\n",
            "Epoch 2/6 \t loss=158.5201 \t val_loss=217.5646  \t val_acc=0.8524  \t time=158.14s\n",
            "Epoch 2/6 \t loss=159.9387 \t val_loss=217.1384  \t val_acc=0.8529  \t time=159.49s\n",
            "Epoch 2/6 \t loss=161.0869 \t val_loss=216.8984  \t val_acc=0.8535  \t time=160.84s\n",
            "Epoch 2/6 \t loss=162.5010 \t val_loss=216.7883  \t val_acc=0.8537  \t time=162.19s\n",
            "Epoch 2/6 \t loss=164.0872 \t val_loss=216.6552  \t val_acc=0.8535  \t time=163.53s\n",
            "Epoch 2/6 \t loss=165.3028 \t val_loss=216.4311  \t val_acc=0.8543  \t time=164.88s\n",
            "Epoch 2/6 \t loss=166.6427 \t val_loss=216.2270  \t val_acc=0.8546  \t time=166.23s\n",
            "Epoch 2/6 \t loss=167.8907 \t val_loss=216.1007  \t val_acc=0.8544  \t time=167.59s\n",
            "Epoch 2/6 \t loss=169.0177 \t val_loss=215.8623  \t val_acc=0.8548  \t time=168.94s\n",
            "Epoch 2/6 \t loss=170.4212 \t val_loss=215.6981  \t val_acc=0.8553  \t time=170.29s\n",
            "Epoch 2/6 \t loss=171.6776 \t val_loss=215.7465  \t val_acc=0.8548  \t time=171.64s\n",
            "Epoch 2/6 \t loss=172.7865 \t val_loss=215.4273  \t val_acc=0.8553  \t time=173.26s\n",
            "Epoch 2/6 \t loss=174.0165 \t val_loss=214.6804  \t val_acc=0.8557  \t time=174.62s\n",
            "Epoch 2/6 \t loss=175.2446 \t val_loss=214.0567  \t val_acc=0.8563  \t time=175.97s\n",
            "Epoch 2/6 \t loss=176.6293 \t val_loss=213.8055  \t val_acc=0.8567  \t time=177.32s\n",
            "Epoch 2/6 \t loss=177.8785 \t val_loss=213.7558  \t val_acc=0.8561  \t time=178.67s\n",
            "Epoch 2/6 \t loss=179.2447 \t val_loss=213.4991  \t val_acc=0.8559  \t time=180.02s\n",
            "Epoch 2/6 \t loss=180.5187 \t val_loss=213.8171  \t val_acc=0.8566  \t time=181.37s\n",
            "Epoch 2/6 \t loss=181.8386 \t val_loss=214.6051  \t val_acc=0.8555  \t time=182.72s\n",
            "Epoch 2/6 \t loss=183.0573 \t val_loss=215.6904  \t val_acc=0.8545  \t time=184.07s\n",
            "Epoch 2/6 \t loss=184.4152 \t val_loss=216.0128  \t val_acc=0.8541  \t time=185.42s\n",
            "Epoch 2/6 \t loss=185.5071 \t val_loss=215.2211  \t val_acc=0.8544  \t time=186.77s\n",
            "Epoch 2/6 \t loss=186.7828 \t val_loss=213.9168  \t val_acc=0.8557  \t time=188.12s\n",
            "Epoch 2/6 \t loss=187.9678 \t val_loss=212.9688  \t val_acc=0.8563  \t time=189.47s\n",
            "Epoch 2/6 \t loss=189.1604 \t val_loss=213.0174  \t val_acc=0.8553  \t time=190.83s\n",
            "Epoch 2/6 \t loss=190.4131 \t val_loss=213.7042  \t val_acc=0.8548  \t time=192.18s\n",
            "Epoch 2/6 \t loss=191.6935 \t val_loss=213.8451  \t val_acc=0.8546  \t time=193.52s\n",
            "Epoch 2/6 \t loss=192.9792 \t val_loss=213.8651  \t val_acc=0.8549  \t time=194.87s\n",
            "Epoch 2/6 \t loss=194.2748 \t val_loss=212.5151  \t val_acc=0.8558  \t time=196.23s\n",
            "Epoch 2/6 \t loss=195.6504 \t val_loss=211.5911  \t val_acc=0.8558  \t time=197.58s\n",
            "Epoch 2/6 \t loss=196.8015 \t val_loss=211.5566  \t val_acc=0.8553  \t time=199.20s\n",
            "Epoch 2/6 \t loss=198.2340 \t val_loss=212.2895  \t val_acc=0.8553  \t time=200.55s\n",
            "Epoch 2/6 \t loss=199.5984 \t val_loss=213.1355  \t val_acc=0.8550  \t time=201.90s\n",
            "Epoch 2/6 \t loss=200.9041 \t val_loss=213.0215  \t val_acc=0.8555  \t time=203.25s\n",
            "Epoch 2/6 \t loss=202.1314 \t val_loss=212.0959  \t val_acc=0.8560  \t time=204.60s\n",
            "Epoch 2/6 \t loss=203.5963 \t val_loss=211.2333  \t val_acc=0.8576  \t time=205.95s\n",
            "Epoch 2/6 \t loss=204.8810 \t val_loss=210.7249  \t val_acc=0.8573  \t time=207.31s\n",
            "Epoch 2/6 \t loss=206.1700 \t val_loss=210.3877  \t val_acc=0.8579  \t time=208.66s\n",
            "Epoch 2/6 \t loss=207.1930 \t val_loss=210.3303  \t val_acc=0.8575  \t time=210.01s\n",
            "Epoch 2/6 \t loss=208.5036 \t val_loss=210.6545  \t val_acc=0.8576  \t time=211.36s\n",
            "Epoch 2/6 \t loss=209.8010 \t val_loss=211.1711  \t val_acc=0.8576  \t time=212.71s\n",
            "Epoch 2/6 \t loss=211.0761 \t val_loss=211.4380  \t val_acc=0.8579  \t time=214.06s\n",
            "Epoch 2/6 \t loss=212.3198 \t val_loss=211.8618  \t val_acc=0.8574  \t time=215.40s\n",
            "Epoch 2/6 \t loss=213.7221 \t val_loss=211.4150  \t val_acc=0.8568  \t time=216.75s\n",
            "Epoch 2/6 \t loss=215.0328 \t val_loss=210.8351  \t val_acc=0.8571  \t time=218.10s\n",
            "Epoch 2/6 \t loss=216.2478 \t val_loss=211.3333  \t val_acc=0.8558  \t time=219.45s\n",
            "Epoch 2/6 \t loss=217.4982 \t val_loss=212.8123  \t val_acc=0.8540  \t time=220.80s\n",
            "Epoch 2/6 \t loss=218.6983 \t val_loss=213.1753  \t val_acc=0.8530  \t time=222.15s\n",
            "Epoch 2/6 \t loss=219.2602 \t val_loss=213.3363  \t val_acc=0.8519  \t time=223.48s\n",
            "Epoch 3/6 \t loss=1.4038 \t val_loss=212.3878  \t val_acc=0.8538  \t time=1.62s\n",
            "Epoch 3/6 \t loss=2.5499 \t val_loss=211.1802  \t val_acc=0.8555  \t time=2.98s\n",
            "Epoch 3/6 \t loss=3.6556 \t val_loss=209.6067  \t val_acc=0.8580  \t time=4.33s\n",
            "Epoch 3/6 \t loss=4.8575 \t val_loss=209.5629  \t val_acc=0.8589  \t time=5.68s\n",
            "Epoch 3/6 \t loss=6.1216 \t val_loss=209.8392  \t val_acc=0.8596  \t time=7.03s\n",
            "Epoch 3/6 \t loss=7.3495 \t val_loss=210.0459  \t val_acc=0.8595  \t time=8.38s\n",
            "Epoch 3/6 \t loss=8.7379 \t val_loss=209.7671  \t val_acc=0.8588  \t time=9.73s\n",
            "Epoch 3/6 \t loss=9.8296 \t val_loss=209.4767  \t val_acc=0.8579  \t time=11.08s\n",
            "Epoch 3/6 \t loss=10.8619 \t val_loss=208.9027  \t val_acc=0.8581  \t time=12.44s\n",
            "Epoch 3/6 \t loss=12.0863 \t val_loss=208.2609  \t val_acc=0.8588  \t time=13.79s\n",
            "Epoch 3/6 \t loss=13.4529 \t val_loss=208.3639  \t val_acc=0.8574  \t time=15.14s\n",
            "Epoch 3/6 \t loss=14.6634 \t val_loss=208.6123  \t val_acc=0.8575  \t time=16.49s\n",
            "Epoch 3/6 \t loss=16.1852 \t val_loss=208.3176  \t val_acc=0.8576  \t time=17.84s\n",
            "Epoch 3/6 \t loss=17.4081 \t val_loss=207.9116  \t val_acc=0.8577  \t time=19.19s\n",
            "Epoch 3/6 \t loss=18.6761 \t val_loss=207.4743  \t val_acc=0.8574  \t time=20.54s\n",
            "Epoch 3/6 \t loss=19.8609 \t val_loss=207.5769  \t val_acc=0.8574  \t time=21.89s\n",
            "Epoch 3/6 \t loss=21.0819 \t val_loss=208.1795  \t val_acc=0.8572  \t time=23.24s\n",
            "Epoch 3/6 \t loss=22.2622 \t val_loss=209.1077  \t val_acc=0.8572  \t time=24.59s\n",
            "Epoch 3/6 \t loss=23.4930 \t val_loss=210.3903  \t val_acc=0.8566  \t time=25.94s\n",
            "Epoch 3/6 \t loss=24.7992 \t val_loss=210.9730  \t val_acc=0.8565  \t time=27.54s\n",
            "Epoch 3/6 \t loss=25.9142 \t val_loss=210.5387  \t val_acc=0.8571  \t time=28.89s\n",
            "Epoch 3/6 \t loss=27.1806 \t val_loss=209.5927  \t val_acc=0.8575  \t time=30.24s\n",
            "Epoch 3/6 \t loss=28.4599 \t val_loss=208.1320  \t val_acc=0.8596  \t time=31.59s\n",
            "Epoch 3/6 \t loss=29.5999 \t val_loss=207.2300  \t val_acc=0.8592  \t time=32.94s\n",
            "Epoch 3/6 \t loss=30.7920 \t val_loss=206.3503  \t val_acc=0.8596  \t time=34.29s\n",
            "Epoch 3/6 \t loss=31.9134 \t val_loss=206.2776  \t val_acc=0.8593  \t time=35.64s\n",
            "Epoch 3/6 \t loss=33.0872 \t val_loss=206.8688  \t val_acc=0.8592  \t time=36.99s\n",
            "Epoch 3/6 \t loss=34.2710 \t val_loss=207.3657  \t val_acc=0.8583  \t time=38.33s\n",
            "Epoch 3/6 \t loss=35.5180 \t val_loss=206.9495  \t val_acc=0.8590  \t time=39.68s\n",
            "Epoch 3/6 \t loss=36.7396 \t val_loss=206.5417  \t val_acc=0.8588  \t time=41.04s\n",
            "Epoch 3/6 \t loss=37.9970 \t val_loss=205.7789  \t val_acc=0.8587  \t time=42.39s\n",
            "Epoch 3/6 \t loss=38.9988 \t val_loss=205.6439  \t val_acc=0.8590  \t time=43.74s\n",
            "Epoch 3/6 \t loss=40.0688 \t val_loss=205.4586  \t val_acc=0.8595  \t time=45.09s\n",
            "Epoch 3/6 \t loss=41.2962 \t val_loss=205.3436  \t val_acc=0.8607  \t time=46.44s\n",
            "Epoch 3/6 \t loss=42.4612 \t val_loss=205.5658  \t val_acc=0.8599  \t time=47.79s\n",
            "Epoch 3/6 \t loss=43.6496 \t val_loss=206.2395  \t val_acc=0.8601  \t time=49.14s\n",
            "Epoch 3/6 \t loss=44.9810 \t val_loss=207.0191  \t val_acc=0.8597  \t time=50.49s\n",
            "Epoch 3/6 \t loss=46.4005 \t val_loss=206.2418  \t val_acc=0.8603  \t time=51.84s\n",
            "Epoch 3/6 \t loss=47.5700 \t val_loss=204.7543  \t val_acc=0.8604  \t time=53.44s\n",
            "Epoch 3/6 \t loss=48.7295 \t val_loss=204.1799  \t val_acc=0.8607  \t time=54.79s\n",
            "Epoch 3/6 \t loss=49.8283 \t val_loss=204.6142  \t val_acc=0.8593  \t time=56.15s\n",
            "Epoch 3/6 \t loss=50.8720 \t val_loss=205.7937  \t val_acc=0.8587  \t time=57.50s\n",
            "Epoch 3/6 \t loss=52.1157 \t val_loss=206.1691  \t val_acc=0.8581  \t time=58.85s\n",
            "Epoch 3/6 \t loss=53.4034 \t val_loss=205.8677  \t val_acc=0.8587  \t time=60.20s\n",
            "Epoch 3/6 \t loss=54.5106 \t val_loss=205.1327  \t val_acc=0.8599  \t time=61.56s\n",
            "Epoch 3/6 \t loss=55.4748 \t val_loss=205.1528  \t val_acc=0.8594  \t time=62.91s\n",
            "Epoch 3/6 \t loss=56.5279 \t val_loss=205.1765  \t val_acc=0.8588  \t time=64.26s\n",
            "Epoch 3/6 \t loss=57.7220 \t val_loss=205.0706  \t val_acc=0.8588  \t time=65.61s\n",
            "Epoch 3/6 \t loss=58.8249 \t val_loss=204.6788  \t val_acc=0.8591  \t time=66.96s\n",
            "Epoch 3/6 \t loss=60.0174 \t val_loss=204.6688  \t val_acc=0.8596  \t time=68.30s\n",
            "Epoch 3/6 \t loss=61.1350 \t val_loss=204.8799  \t val_acc=0.8597  \t time=69.66s\n",
            "Epoch 3/6 \t loss=62.3885 \t val_loss=205.0605  \t val_acc=0.8603  \t time=71.02s\n",
            "Epoch 3/6 \t loss=63.5233 \t val_loss=204.9135  \t val_acc=0.8609  \t time=72.37s\n",
            "Epoch 3/6 \t loss=64.7513 \t val_loss=204.5883  \t val_acc=0.8609  \t time=73.72s\n",
            "Epoch 3/6 \t loss=66.1241 \t val_loss=204.3180  \t val_acc=0.8613  \t time=75.07s\n",
            "Epoch 3/6 \t loss=67.2956 \t val_loss=203.8474  \t val_acc=0.8611  \t time=76.42s\n",
            "Epoch 3/6 \t loss=68.4839 \t val_loss=203.1908  \t val_acc=0.8614  \t time=78.04s\n",
            "Epoch 3/6 \t loss=69.8452 \t val_loss=202.0290  \t val_acc=0.8618  \t time=79.40s\n",
            "Epoch 3/6 \t loss=70.9968 \t val_loss=201.3143  \t val_acc=0.8616  \t time=80.75s\n",
            "Epoch 3/6 \t loss=72.2656 \t val_loss=201.4701  \t val_acc=0.8617  \t time=82.10s\n",
            "Epoch 3/6 \t loss=73.3948 \t val_loss=202.3004  \t val_acc=0.8624  \t time=83.45s\n",
            "Epoch 3/6 \t loss=74.5323 \t val_loss=204.1458  \t val_acc=0.8616  \t time=84.80s\n",
            "Epoch 3/6 \t loss=75.7617 \t val_loss=206.4748  \t val_acc=0.8595  \t time=86.15s\n",
            "Epoch 3/6 \t loss=77.0501 \t val_loss=206.1984  \t val_acc=0.8598  \t time=87.50s\n",
            "Epoch 3/6 \t loss=78.3549 \t val_loss=203.9006  \t val_acc=0.8614  \t time=88.85s\n",
            "Epoch 3/6 \t loss=79.5280 \t val_loss=201.9730  \t val_acc=0.8626  \t time=90.20s\n",
            "Epoch 3/6 \t loss=80.8394 \t val_loss=201.7157  \t val_acc=0.8621  \t time=91.55s\n",
            "Epoch 3/6 \t loss=82.0587 \t val_loss=202.3840  \t val_acc=0.8619  \t time=92.89s\n",
            "Epoch 3/6 \t loss=83.0432 \t val_loss=203.4157  \t val_acc=0.8612  \t time=94.24s\n",
            "Epoch 3/6 \t loss=84.1398 \t val_loss=203.7031  \t val_acc=0.8607  \t time=95.59s\n",
            "Epoch 3/6 \t loss=85.3017 \t val_loss=203.5883  \t val_acc=0.8602  \t time=96.94s\n",
            "Epoch 3/6 \t loss=86.4286 \t val_loss=203.1477  \t val_acc=0.8606  \t time=98.29s\n",
            "Epoch 3/6 \t loss=87.6599 \t val_loss=202.8594  \t val_acc=0.8615  \t time=99.64s\n",
            "Epoch 3/6 \t loss=88.7931 \t val_loss=202.9417  \t val_acc=0.8618  \t time=100.99s\n",
            "Epoch 3/6 \t loss=89.9062 \t val_loss=202.6842  \t val_acc=0.8611  \t time=102.34s\n",
            "Epoch 3/6 \t loss=91.1925 \t val_loss=202.1678  \t val_acc=0.8608  \t time=103.95s\n",
            "Epoch 3/6 \t loss=92.1212 \t val_loss=201.4144  \t val_acc=0.8611  \t time=105.30s\n",
            "Epoch 3/6 \t loss=93.1883 \t val_loss=200.7557  \t val_acc=0.8613  \t time=106.65s\n",
            "Epoch 3/6 \t loss=94.1962 \t val_loss=200.5850  \t val_acc=0.8616  \t time=108.00s\n",
            "Epoch 3/6 \t loss=95.3336 \t val_loss=200.7573  \t val_acc=0.8621  \t time=109.36s\n",
            "Epoch 3/6 \t loss=96.6078 \t val_loss=201.0850  \t val_acc=0.8617  \t time=110.71s\n",
            "Epoch 3/6 \t loss=97.7310 \t val_loss=200.9106  \t val_acc=0.8616  \t time=112.06s\n",
            "Epoch 3/6 \t loss=98.9166 \t val_loss=200.5579  \t val_acc=0.8612  \t time=113.41s\n",
            "Epoch 3/6 \t loss=99.9662 \t val_loss=200.0733  \t val_acc=0.8619  \t time=114.76s\n",
            "Epoch 3/6 \t loss=100.9902 \t val_loss=199.9591  \t val_acc=0.8621  \t time=116.10s\n",
            "Epoch 3/6 \t loss=102.0535 \t val_loss=200.3828  \t val_acc=0.8618  \t time=117.45s\n",
            "Epoch 3/6 \t loss=103.0861 \t val_loss=200.8857  \t val_acc=0.8616  \t time=118.80s\n",
            "Epoch 3/6 \t loss=104.1454 \t val_loss=201.4056  \t val_acc=0.8607  \t time=120.16s\n",
            "Epoch 3/6 \t loss=105.1003 \t val_loss=200.9435  \t val_acc=0.8609  \t time=121.51s\n",
            "Epoch 3/6 \t loss=106.1174 \t val_loss=199.5960  \t val_acc=0.8630  \t time=122.86s\n",
            "Epoch 3/6 \t loss=107.1157 \t val_loss=198.9819  \t val_acc=0.8629  \t time=124.21s\n",
            "Epoch 3/6 \t loss=108.3750 \t val_loss=199.1774  \t val_acc=0.8620  \t time=125.56s\n",
            "Epoch 3/6 \t loss=109.6701 \t val_loss=199.4601  \t val_acc=0.8620  \t time=126.91s\n",
            "Epoch 3/6 \t loss=110.8869 \t val_loss=199.6893  \t val_acc=0.8617  \t time=128.52s\n",
            "Epoch 3/6 \t loss=112.1312 \t val_loss=200.2921  \t val_acc=0.8611  \t time=129.88s\n",
            "Epoch 3/6 \t loss=113.0939 \t val_loss=200.3269  \t val_acc=0.8605  \t time=131.23s\n",
            "Epoch 3/6 \t loss=114.0056 \t val_loss=199.9836  \t val_acc=0.8613  \t time=132.58s\n",
            "Epoch 3/6 \t loss=115.1196 \t val_loss=198.8007  \t val_acc=0.8620  \t time=133.93s\n",
            "Epoch 3/6 \t loss=116.4026 \t val_loss=197.7000  \t val_acc=0.8630  \t time=135.28s\n",
            "Epoch 3/6 \t loss=117.6555 \t val_loss=197.8229  \t val_acc=0.8628  \t time=136.63s\n",
            "Epoch 3/6 \t loss=118.8653 \t val_loss=198.7630  \t val_acc=0.8635  \t time=137.98s\n",
            "Epoch 3/6 \t loss=119.9574 \t val_loss=199.3693  \t val_acc=0.8620  \t time=139.34s\n",
            "Epoch 3/6 \t loss=121.2065 \t val_loss=199.3401  \t val_acc=0.8623  \t time=140.69s\n",
            "Epoch 3/6 \t loss=122.4056 \t val_loss=199.3975  \t val_acc=0.8625  \t time=142.04s\n",
            "Epoch 3/6 \t loss=123.4825 \t val_loss=198.9743  \t val_acc=0.8632  \t time=143.39s\n",
            "Epoch 3/6 \t loss=124.5902 \t val_loss=198.6724  \t val_acc=0.8630  \t time=144.74s\n",
            "Epoch 3/6 \t loss=125.7553 \t val_loss=197.8589  \t val_acc=0.8635  \t time=146.09s\n",
            "Epoch 3/6 \t loss=126.8341 \t val_loss=197.0499  \t val_acc=0.8645  \t time=147.44s\n",
            "Epoch 3/6 \t loss=128.0364 \t val_loss=197.1634  \t val_acc=0.8636  \t time=148.79s\n",
            "Epoch 3/6 \t loss=129.2062 \t val_loss=198.1933  \t val_acc=0.8633  \t time=150.14s\n",
            "Epoch 3/6 \t loss=130.2621 \t val_loss=198.9653  \t val_acc=0.8626  \t time=151.49s\n",
            "Epoch 3/6 \t loss=131.2902 \t val_loss=199.1848  \t val_acc=0.8624  \t time=152.84s\n",
            "Epoch 3/6 \t loss=132.4744 \t val_loss=198.7846  \t val_acc=0.8631  \t time=154.45s\n",
            "Epoch 3/6 \t loss=133.5891 \t val_loss=197.5816  \t val_acc=0.8641  \t time=155.80s\n",
            "Epoch 3/6 \t loss=134.6648 \t val_loss=196.8423  \t val_acc=0.8651  \t time=157.15s\n",
            "Epoch 3/6 \t loss=135.7732 \t val_loss=196.2266  \t val_acc=0.8646  \t time=158.50s\n",
            "Epoch 3/6 \t loss=136.9383 \t val_loss=196.2258  \t val_acc=0.8647  \t time=159.85s\n",
            "Epoch 3/6 \t loss=138.1072 \t val_loss=196.4360  \t val_acc=0.8641  \t time=161.20s\n",
            "Epoch 3/6 \t loss=139.2203 \t val_loss=196.7633  \t val_acc=0.8640  \t time=162.55s\n",
            "Epoch 3/6 \t loss=140.3066 \t val_loss=196.7359  \t val_acc=0.8636  \t time=163.89s\n",
            "Epoch 3/6 \t loss=141.4220 \t val_loss=196.8062  \t val_acc=0.8632  \t time=165.25s\n",
            "Epoch 3/6 \t loss=142.5499 \t val_loss=196.7772  \t val_acc=0.8638  \t time=166.60s\n",
            "Epoch 3/6 \t loss=143.6427 \t val_loss=196.9024  \t val_acc=0.8637  \t time=167.95s\n",
            "Epoch 3/6 \t loss=144.8191 \t val_loss=196.7806  \t val_acc=0.8630  \t time=169.30s\n",
            "Epoch 3/6 \t loss=145.8438 \t val_loss=196.5472  \t val_acc=0.8639  \t time=170.65s\n",
            "Epoch 3/6 \t loss=146.9321 \t val_loss=196.2676  \t val_acc=0.8635  \t time=172.00s\n",
            "Epoch 3/6 \t loss=148.1200 \t val_loss=195.6542  \t val_acc=0.8643  \t time=173.35s\n",
            "Epoch 3/6 \t loss=149.3529 \t val_loss=195.4407  \t val_acc=0.8644  \t time=174.69s\n",
            "Epoch 3/6 \t loss=150.4354 \t val_loss=195.6808  \t val_acc=0.8638  \t time=176.04s\n",
            "Epoch 3/6 \t loss=151.7621 \t val_loss=196.2816  \t val_acc=0.8638  \t time=177.39s\n",
            "Epoch 3/6 \t loss=152.7607 \t val_loss=196.1341  \t val_acc=0.8643  \t time=178.74s\n",
            "Epoch 3/6 \t loss=153.6816 \t val_loss=195.5507  \t val_acc=0.8648  \t time=180.35s\n",
            "Epoch 3/6 \t loss=154.8198 \t val_loss=195.3685  \t val_acc=0.8643  \t time=181.70s\n",
            "Epoch 3/6 \t loss=155.8907 \t val_loss=195.2634  \t val_acc=0.8643  \t time=183.05s\n",
            "Epoch 3/6 \t loss=157.2253 \t val_loss=195.2792  \t val_acc=0.8644  \t time=184.40s\n",
            "Epoch 3/6 \t loss=158.2621 \t val_loss=195.2708  \t val_acc=0.8650  \t time=185.75s\n",
            "Epoch 3/6 \t loss=159.3253 \t val_loss=195.6103  \t val_acc=0.8655  \t time=187.10s\n",
            "Epoch 3/6 \t loss=160.5725 \t val_loss=195.5828  \t val_acc=0.8655  \t time=188.45s\n",
            "Epoch 3/6 \t loss=161.5665 \t val_loss=195.6378  \t val_acc=0.8657  \t time=189.81s\n",
            "Epoch 3/6 \t loss=162.6623 \t val_loss=195.4946  \t val_acc=0.8657  \t time=191.16s\n",
            "Epoch 3/6 \t loss=163.8357 \t val_loss=194.9603  \t val_acc=0.8658  \t time=192.51s\n",
            "Epoch 3/6 \t loss=164.7253 \t val_loss=194.9748  \t val_acc=0.8648  \t time=193.86s\n",
            "Epoch 3/6 \t loss=165.6554 \t val_loss=196.0039  \t val_acc=0.8639  \t time=195.21s\n",
            "Epoch 3/6 \t loss=166.6798 \t val_loss=197.4144  \t val_acc=0.8628  \t time=196.56s\n",
            "Epoch 3/6 \t loss=167.6568 \t val_loss=198.0355  \t val_acc=0.8632  \t time=197.92s\n",
            "Epoch 3/6 \t loss=168.7633 \t val_loss=197.1422  \t val_acc=0.8632  \t time=199.27s\n",
            "Epoch 3/6 \t loss=169.8948 \t val_loss=195.4633  \t val_acc=0.8647  \t time=200.62s\n",
            "Epoch 3/6 \t loss=171.0171 \t val_loss=194.5515  \t val_acc=0.8667  \t time=201.97s\n",
            "Epoch 3/6 \t loss=172.0785 \t val_loss=195.7487  \t val_acc=0.8660  \t time=203.32s\n",
            "Epoch 3/6 \t loss=173.1478 \t val_loss=196.6158  \t val_acc=0.8652  \t time=204.68s\n",
            "Epoch 3/6 \t loss=174.2849 \t val_loss=195.9223  \t val_acc=0.8653  \t time=206.28s\n",
            "Epoch 3/6 \t loss=175.3354 \t val_loss=194.0165  \t val_acc=0.8667  \t time=207.63s\n",
            "Epoch 3/6 \t loss=176.5162 \t val_loss=193.0150  \t val_acc=0.8666  \t time=208.98s\n",
            "Epoch 3/6 \t loss=177.7596 \t val_loss=193.0963  \t val_acc=0.8655  \t time=210.33s\n",
            "Epoch 3/6 \t loss=178.8052 \t val_loss=193.6014  \t val_acc=0.8651  \t time=211.68s\n",
            "Epoch 3/6 \t loss=179.8615 \t val_loss=194.4166  \t val_acc=0.8641  \t time=213.03s\n",
            "Epoch 3/6 \t loss=181.0473 \t val_loss=194.9306  \t val_acc=0.8630  \t time=214.38s\n",
            "Epoch 3/6 \t loss=182.1308 \t val_loss=195.3065  \t val_acc=0.8631  \t time=215.73s\n",
            "Epoch 3/6 \t loss=183.2085 \t val_loss=194.9891  \t val_acc=0.8637  \t time=217.09s\n",
            "Epoch 3/6 \t loss=184.3592 \t val_loss=194.2756  \t val_acc=0.8651  \t time=218.45s\n",
            "Epoch 3/6 \t loss=185.4449 \t val_loss=193.9143  \t val_acc=0.8659  \t time=219.80s\n",
            "Epoch 3/6 \t loss=186.5135 \t val_loss=194.8101  \t val_acc=0.8659  \t time=221.16s\n",
            "Epoch 3/6 \t loss=187.8046 \t val_loss=196.0033  \t val_acc=0.8644  \t time=222.51s\n",
            "Epoch 3/6 \t loss=188.3817 \t val_loss=196.5264  \t val_acc=0.8646  \t time=223.84s\n",
            "Epoch 4/6 \t loss=1.3072 \t val_loss=195.1010  \t val_acc=0.8658  \t time=1.35s\n",
            "Epoch 4/6 \t loss=2.6673 \t val_loss=193.0759  \t val_acc=0.8672  \t time=2.70s\n",
            "Epoch 4/6 \t loss=3.6803 \t val_loss=191.6616  \t val_acc=0.8676  \t time=4.06s\n",
            "Epoch 4/6 \t loss=4.8423 \t val_loss=191.7514  \t val_acc=0.8668  \t time=5.41s\n",
            "Epoch 4/6 \t loss=5.8615 \t val_loss=193.2738  \t val_acc=0.8664  \t time=7.02s\n",
            "Epoch 4/6 \t loss=6.7969 \t val_loss=194.6782  \t val_acc=0.8646  \t time=8.37s\n",
            "Epoch 4/6 \t loss=7.7384 \t val_loss=195.2408  \t val_acc=0.8639  \t time=9.72s\n",
            "Epoch 4/6 \t loss=8.9636 \t val_loss=194.4603  \t val_acc=0.8653  \t time=11.07s\n",
            "Epoch 4/6 \t loss=10.0277 \t val_loss=193.1035  \t val_acc=0.8666  \t time=12.42s\n",
            "Epoch 4/6 \t loss=11.1031 \t val_loss=191.8751  \t val_acc=0.8678  \t time=13.77s\n",
            "Epoch 4/6 \t loss=12.1486 \t val_loss=191.8533  \t val_acc=0.8676  \t time=15.12s\n",
            "Epoch 4/6 \t loss=13.1638 \t val_loss=192.5536  \t val_acc=0.8682  \t time=16.47s\n",
            "Epoch 4/6 \t loss=14.0809 \t val_loss=192.6210  \t val_acc=0.8679  \t time=17.82s\n",
            "Epoch 4/6 \t loss=15.1503 \t val_loss=192.1679  \t val_acc=0.8680  \t time=19.17s\n",
            "Epoch 4/6 \t loss=16.2251 \t val_loss=191.6275  \t val_acc=0.8676  \t time=20.52s\n",
            "Epoch 4/6 \t loss=17.2608 \t val_loss=190.9801  \t val_acc=0.8674  \t time=21.87s\n",
            "Epoch 4/6 \t loss=18.1428 \t val_loss=190.9934  \t val_acc=0.8672  \t time=23.22s\n",
            "Epoch 4/6 \t loss=19.1849 \t val_loss=191.1142  \t val_acc=0.8673  \t time=24.57s\n",
            "Epoch 4/6 \t loss=20.1814 \t val_loss=191.2106  \t val_acc=0.8678  \t time=25.92s\n",
            "Epoch 4/6 \t loss=21.2249 \t val_loss=191.5226  \t val_acc=0.8680  \t time=27.27s\n",
            "Epoch 4/6 \t loss=22.2177 \t val_loss=191.5719  \t val_acc=0.8680  \t time=28.62s\n",
            "Epoch 4/6 \t loss=23.1859 \t val_loss=191.0103  \t val_acc=0.8683  \t time=29.97s\n",
            "Epoch 4/6 \t loss=24.0645 \t val_loss=190.9063  \t val_acc=0.8682  \t time=31.32s\n",
            "Epoch 4/6 \t loss=24.9892 \t val_loss=191.1700  \t val_acc=0.8682  \t time=32.93s\n",
            "Epoch 4/6 \t loss=26.0308 \t val_loss=191.4226  \t val_acc=0.8681  \t time=34.28s\n",
            "Epoch 4/6 \t loss=27.1067 \t val_loss=191.5527  \t val_acc=0.8678  \t time=35.64s\n",
            "Epoch 4/6 \t loss=28.0752 \t val_loss=191.2675  \t val_acc=0.8677  \t time=36.99s\n",
            "Epoch 4/6 \t loss=29.1485 \t val_loss=190.7405  \t val_acc=0.8691  \t time=38.34s\n",
            "Epoch 4/6 \t loss=30.0353 \t val_loss=190.1517  \t val_acc=0.8687  \t time=39.68s\n",
            "Epoch 4/6 \t loss=30.9060 \t val_loss=190.2718  \t val_acc=0.8687  \t time=41.03s\n",
            "Epoch 4/6 \t loss=31.7710 \t val_loss=190.8449  \t val_acc=0.8680  \t time=42.38s\n",
            "Epoch 4/6 \t loss=32.7966 \t val_loss=192.0314  \t val_acc=0.8662  \t time=43.73s\n",
            "Epoch 4/6 \t loss=33.8112 \t val_loss=192.2456  \t val_acc=0.8656  \t time=45.08s\n",
            "Epoch 4/6 \t loss=35.0117 \t val_loss=191.9170  \t val_acc=0.8649  \t time=46.43s\n",
            "Epoch 4/6 \t loss=35.8816 \t val_loss=191.1754  \t val_acc=0.8658  \t time=47.78s\n",
            "Epoch 4/6 \t loss=37.1260 \t val_loss=191.0940  \t val_acc=0.8677  \t time=49.13s\n",
            "Epoch 4/6 \t loss=38.1909 \t val_loss=191.5283  \t val_acc=0.8668  \t time=50.48s\n",
            "Epoch 4/6 \t loss=39.2446 \t val_loss=191.5252  \t val_acc=0.8667  \t time=51.83s\n",
            "Epoch 4/6 \t loss=40.3654 \t val_loss=190.8931  \t val_acc=0.8676  \t time=53.19s\n",
            "Epoch 4/6 \t loss=41.4761 \t val_loss=189.9885  \t val_acc=0.8669  \t time=54.55s\n",
            "Epoch 4/6 \t loss=42.3081 \t val_loss=190.0195  \t val_acc=0.8679  \t time=55.90s\n",
            "Epoch 4/6 \t loss=43.4162 \t val_loss=190.2096  \t val_acc=0.8678  \t time=57.50s\n",
            "Epoch 4/6 \t loss=44.5680 \t val_loss=190.0760  \t val_acc=0.8683  \t time=58.85s\n",
            "Epoch 4/6 \t loss=45.6527 \t val_loss=190.5344  \t val_acc=0.8669  \t time=60.20s\n",
            "Epoch 4/6 \t loss=46.5300 \t val_loss=191.8775  \t val_acc=0.8671  \t time=61.55s\n",
            "Epoch 4/6 \t loss=47.8217 \t val_loss=193.0676  \t val_acc=0.8661  \t time=62.90s\n",
            "Epoch 4/6 \t loss=48.7100 \t val_loss=193.8201  \t val_acc=0.8658  \t time=64.25s\n",
            "Epoch 4/6 \t loss=49.7635 \t val_loss=193.3117  \t val_acc=0.8658  \t time=65.60s\n",
            "Epoch 4/6 \t loss=50.8488 \t val_loss=191.7964  \t val_acc=0.8665  \t time=66.95s\n",
            "Epoch 4/6 \t loss=51.8732 \t val_loss=189.9649  \t val_acc=0.8687  \t time=68.30s\n",
            "Epoch 4/6 \t loss=53.0158 \t val_loss=188.6435  \t val_acc=0.8690  \t time=69.65s\n",
            "Epoch 4/6 \t loss=54.2085 \t val_loss=188.3073  \t val_acc=0.8697  \t time=71.00s\n",
            "Epoch 4/6 \t loss=55.1534 \t val_loss=188.7081  \t val_acc=0.8693  \t time=72.35s\n",
            "Epoch 4/6 \t loss=56.1042 \t val_loss=189.2558  \t val_acc=0.8699  \t time=73.70s\n",
            "Epoch 4/6 \t loss=57.0035 \t val_loss=190.1261  \t val_acc=0.8690  \t time=75.05s\n",
            "Epoch 4/6 \t loss=58.1166 \t val_loss=190.8715  \t val_acc=0.8684  \t time=76.41s\n",
            "Epoch 4/6 \t loss=59.2318 \t val_loss=191.0384  \t val_acc=0.8685  \t time=77.76s\n",
            "Epoch 4/6 \t loss=60.3680 \t val_loss=190.5223  \t val_acc=0.8691  \t time=79.11s\n",
            "Epoch 4/6 \t loss=61.3127 \t val_loss=190.4293  \t val_acc=0.8702  \t time=80.46s\n",
            "Epoch 4/6 \t loss=62.1814 \t val_loss=189.7397  \t val_acc=0.8708  \t time=81.81s\n",
            "Epoch 4/6 \t loss=63.3033 \t val_loss=189.1351  \t val_acc=0.8710  \t time=83.41s\n",
            "Epoch 4/6 \t loss=64.3652 \t val_loss=189.1045  \t val_acc=0.8704  \t time=84.77s\n",
            "Epoch 4/6 \t loss=65.5133 \t val_loss=190.1274  \t val_acc=0.8677  \t time=86.12s\n",
            "Epoch 4/6 \t loss=66.6763 \t val_loss=191.3488  \t val_acc=0.8657  \t time=87.47s\n",
            "Epoch 4/6 \t loss=67.7545 \t val_loss=192.0212  \t val_acc=0.8647  \t time=88.82s\n",
            "Epoch 4/6 \t loss=68.7629 \t val_loss=191.2234  \t val_acc=0.8652  \t time=90.17s\n",
            "Epoch 4/6 \t loss=69.6903 \t val_loss=189.2460  \t val_acc=0.8674  \t time=91.52s\n",
            "Epoch 4/6 \t loss=70.7188 \t val_loss=188.4087  \t val_acc=0.8712  \t time=92.87s\n",
            "Epoch 4/6 \t loss=71.7260 \t val_loss=189.0987  \t val_acc=0.8701  \t time=94.22s\n",
            "Epoch 4/6 \t loss=72.7627 \t val_loss=190.6247  \t val_acc=0.8682  \t time=95.57s\n",
            "Epoch 4/6 \t loss=73.7721 \t val_loss=191.3985  \t val_acc=0.8678  \t time=96.92s\n",
            "Epoch 4/6 \t loss=74.6815 \t val_loss=190.5516  \t val_acc=0.8671  \t time=98.27s\n",
            "Epoch 4/6 \t loss=75.7338 \t val_loss=189.4675  \t val_acc=0.8682  \t time=99.62s\n",
            "Epoch 4/6 \t loss=76.8575 \t val_loss=188.2874  \t val_acc=0.8692  \t time=100.97s\n",
            "Epoch 4/6 \t loss=77.8502 \t val_loss=188.4803  \t val_acc=0.8693  \t time=102.32s\n",
            "Epoch 4/6 \t loss=78.9771 \t val_loss=189.4018  \t val_acc=0.8690  \t time=103.67s\n",
            "Epoch 4/6 \t loss=79.9093 \t val_loss=190.2624  \t val_acc=0.8677  \t time=105.03s\n",
            "Epoch 4/6 \t loss=81.0051 \t val_loss=189.8618  \t val_acc=0.8676  \t time=106.39s\n",
            "Epoch 4/6 \t loss=82.0073 \t val_loss=189.0374  \t val_acc=0.8673  \t time=107.73s\n",
            "Epoch 4/6 \t loss=83.1989 \t val_loss=187.6292  \t val_acc=0.8692  \t time=109.34s\n",
            "Epoch 4/6 \t loss=84.2360 \t val_loss=187.3786  \t val_acc=0.8704  \t time=110.69s\n",
            "Epoch 4/6 \t loss=85.1851 \t val_loss=188.0112  \t val_acc=0.8702  \t time=112.04s\n",
            "Epoch 4/6 \t loss=86.1509 \t val_loss=189.7999  \t val_acc=0.8694  \t time=113.39s\n",
            "Epoch 4/6 \t loss=87.0792 \t val_loss=190.4946  \t val_acc=0.8693  \t time=114.74s\n",
            "Epoch 4/6 \t loss=88.2573 \t val_loss=188.9605  \t val_acc=0.8699  \t time=116.10s\n",
            "Epoch 4/6 \t loss=89.2961 \t val_loss=187.3034  \t val_acc=0.8702  \t time=117.45s\n",
            "Epoch 4/6 \t loss=90.2417 \t val_loss=186.5516  \t val_acc=0.8706  \t time=118.80s\n",
            "Epoch 4/6 \t loss=91.5134 \t val_loss=186.2877  \t val_acc=0.8709  \t time=120.15s\n",
            "Epoch 4/6 \t loss=92.6579 \t val_loss=186.5955  \t val_acc=0.8708  \t time=121.50s\n",
            "Epoch 4/6 \t loss=93.5845 \t val_loss=187.5302  \t val_acc=0.8704  \t time=122.85s\n",
            "Epoch 4/6 \t loss=94.6383 \t val_loss=188.7027  \t val_acc=0.8698  \t time=124.20s\n",
            "Epoch 4/6 \t loss=95.5860 \t val_loss=189.2854  \t val_acc=0.8696  \t time=125.55s\n",
            "Epoch 4/6 \t loss=96.5504 \t val_loss=188.8574  \t val_acc=0.8700  \t time=126.89s\n",
            "Epoch 4/6 \t loss=97.6131 \t val_loss=187.8203  \t val_acc=0.8709  \t time=128.24s\n",
            "Epoch 4/6 \t loss=98.9216 \t val_loss=186.4473  \t val_acc=0.8712  \t time=129.59s\n",
            "Epoch 4/6 \t loss=100.0572 \t val_loss=185.9032  \t val_acc=0.8711  \t time=130.94s\n",
            "Epoch 4/6 \t loss=101.0499 \t val_loss=186.1285  \t val_acc=0.8716  \t time=132.29s\n",
            "Epoch 4/6 \t loss=102.1909 \t val_loss=187.2052  \t val_acc=0.8707  \t time=133.64s\n",
            "Epoch 4/6 \t loss=103.0659 \t val_loss=188.7630  \t val_acc=0.8694  \t time=135.25s\n",
            "Epoch 4/6 \t loss=104.1984 \t val_loss=190.8421  \t val_acc=0.8671  \t time=136.60s\n",
            "Epoch 4/6 \t loss=105.3643 \t val_loss=191.9153  \t val_acc=0.8659  \t time=137.95s\n",
            "Epoch 4/6 \t loss=106.4939 \t val_loss=191.6754  \t val_acc=0.8659  \t time=139.30s\n",
            "Epoch 4/6 \t loss=107.5353 \t val_loss=189.4217  \t val_acc=0.8683  \t time=140.65s\n",
            "Epoch 4/6 \t loss=108.4248 \t val_loss=187.4773  \t val_acc=0.8702  \t time=142.00s\n",
            "Epoch 4/6 \t loss=109.3525 \t val_loss=186.8784  \t val_acc=0.8712  \t time=143.35s\n",
            "Epoch 4/6 \t loss=110.2929 \t val_loss=186.6418  \t val_acc=0.8701  \t time=144.70s\n",
            "Epoch 4/6 \t loss=111.3533 \t val_loss=186.7011  \t val_acc=0.8704  \t time=146.06s\n",
            "Epoch 4/6 \t loss=112.4877 \t val_loss=186.9631  \t val_acc=0.8706  \t time=147.41s\n",
            "Epoch 4/6 \t loss=113.3650 \t val_loss=187.0675  \t val_acc=0.8689  \t time=148.76s\n",
            "Epoch 4/6 \t loss=114.4055 \t val_loss=187.3204  \t val_acc=0.8681  \t time=150.11s\n",
            "Epoch 4/6 \t loss=115.3778 \t val_loss=187.3511  \t val_acc=0.8689  \t time=151.46s\n",
            "Epoch 4/6 \t loss=116.5258 \t val_loss=186.5225  \t val_acc=0.8715  \t time=152.81s\n",
            "Epoch 4/6 \t loss=117.5316 \t val_loss=185.9391  \t val_acc=0.8715  \t time=154.16s\n",
            "Epoch 4/6 \t loss=118.5450 \t val_loss=186.3543  \t val_acc=0.8716  \t time=155.51s\n",
            "Epoch 4/6 \t loss=119.6636 \t val_loss=186.7787  \t val_acc=0.8707  \t time=156.86s\n",
            "Epoch 4/6 \t loss=120.7742 \t val_loss=186.6095  \t val_acc=0.8708  \t time=158.21s\n",
            "Epoch 4/6 \t loss=121.9086 \t val_loss=185.4277  \t val_acc=0.8714  \t time=159.82s\n",
            "Epoch 4/6 \t loss=122.7793 \t val_loss=184.5953  \t val_acc=0.8726  \t time=161.17s\n",
            "Epoch 4/6 \t loss=123.9144 \t val_loss=184.3733  \t val_acc=0.8724  \t time=162.52s\n",
            "Epoch 4/6 \t loss=124.7758 \t val_loss=184.4338  \t val_acc=0.8721  \t time=163.87s\n",
            "Epoch 4/6 \t loss=125.9202 \t val_loss=184.7482  \t val_acc=0.8721  \t time=165.23s\n",
            "Epoch 4/6 \t loss=126.8034 \t val_loss=184.6836  \t val_acc=0.8720  \t time=166.58s\n",
            "Epoch 4/6 \t loss=127.8409 \t val_loss=184.5259  \t val_acc=0.8715  \t time=167.93s\n",
            "Epoch 4/6 \t loss=128.8540 \t val_loss=184.7344  \t val_acc=0.8715  \t time=169.28s\n",
            "Epoch 4/6 \t loss=129.9828 \t val_loss=185.2462  \t val_acc=0.8705  \t time=170.63s\n",
            "Epoch 4/6 \t loss=131.0626 \t val_loss=185.0350  \t val_acc=0.8704  \t time=171.98s\n",
            "Epoch 4/6 \t loss=132.1131 \t val_loss=184.3397  \t val_acc=0.8710  \t time=173.33s\n",
            "Epoch 4/6 \t loss=133.2078 \t val_loss=183.9759  \t val_acc=0.8715  \t time=174.69s\n",
            "Epoch 4/6 \t loss=134.2641 \t val_loss=183.2300  \t val_acc=0.8728  \t time=176.03s\n",
            "Epoch 4/6 \t loss=135.2087 \t val_loss=182.8915  \t val_acc=0.8741  \t time=177.39s\n",
            "Epoch 4/6 \t loss=136.1035 \t val_loss=182.7541  \t val_acc=0.8738  \t time=178.73s\n",
            "Epoch 4/6 \t loss=137.1878 \t val_loss=183.1839  \t val_acc=0.8733  \t time=180.08s\n",
            "Epoch 4/6 \t loss=138.3696 \t val_loss=184.3229  \t val_acc=0.8725  \t time=181.43s\n",
            "Epoch 4/6 \t loss=139.5071 \t val_loss=184.9763  \t val_acc=0.8717  \t time=182.79s\n",
            "Epoch 4/6 \t loss=140.2447 \t val_loss=185.0460  \t val_acc=0.8718  \t time=184.14s\n",
            "Epoch 4/6 \t loss=141.1491 \t val_loss=184.2040  \t val_acc=0.8721  \t time=185.75s\n",
            "Epoch 4/6 \t loss=142.2327 \t val_loss=183.7423  \t val_acc=0.8727  \t time=187.10s\n",
            "Epoch 4/6 \t loss=143.1418 \t val_loss=183.7634  \t val_acc=0.8720  \t time=188.45s\n",
            "Epoch 4/6 \t loss=144.1935 \t val_loss=183.3675  \t val_acc=0.8719  \t time=189.80s\n",
            "Epoch 4/6 \t loss=145.1018 \t val_loss=183.6324  \t val_acc=0.8721  \t time=191.15s\n",
            "Epoch 4/6 \t loss=146.0767 \t val_loss=184.6261  \t val_acc=0.8713  \t time=192.50s\n",
            "Epoch 4/6 \t loss=147.0836 \t val_loss=185.1374  \t val_acc=0.8703  \t time=193.85s\n",
            "Epoch 4/6 \t loss=148.0455 \t val_loss=185.1678  \t val_acc=0.8711  \t time=195.20s\n",
            "Epoch 4/6 \t loss=149.0825 \t val_loss=185.1584  \t val_acc=0.8716  \t time=196.55s\n",
            "Epoch 4/6 \t loss=149.9821 \t val_loss=184.8442  \t val_acc=0.8719  \t time=197.90s\n",
            "Epoch 4/6 \t loss=150.9918 \t val_loss=184.3238  \t val_acc=0.8723  \t time=199.25s\n",
            "Epoch 4/6 \t loss=152.0383 \t val_loss=183.8238  \t val_acc=0.8729  \t time=200.60s\n",
            "Epoch 4/6 \t loss=152.9782 \t val_loss=182.7853  \t val_acc=0.8735  \t time=201.95s\n",
            "Epoch 4/6 \t loss=154.0062 \t val_loss=182.2571  \t val_acc=0.8737  \t time=203.31s\n",
            "Epoch 4/6 \t loss=154.9542 \t val_loss=182.7682  \t val_acc=0.8729  \t time=204.67s\n",
            "Epoch 4/6 \t loss=155.9148 \t val_loss=184.2442  \t val_acc=0.8722  \t time=206.02s\n",
            "Epoch 4/6 \t loss=157.1900 \t val_loss=185.2934  \t val_acc=0.8715  \t time=207.37s\n",
            "Epoch 4/6 \t loss=158.1515 \t val_loss=185.8245  \t val_acc=0.8714  \t time=208.71s\n",
            "Epoch 4/6 \t loss=159.1811 \t val_loss=184.6309  \t val_acc=0.8725  \t time=210.32s\n",
            "Epoch 4/6 \t loss=160.1342 \t val_loss=183.6711  \t val_acc=0.8734  \t time=211.68s\n",
            "Epoch 4/6 \t loss=161.1683 \t val_loss=182.4667  \t val_acc=0.8743  \t time=213.03s\n",
            "Epoch 4/6 \t loss=162.1050 \t val_loss=182.2378  \t val_acc=0.8740  \t time=214.38s\n",
            "Epoch 4/6 \t loss=163.1797 \t val_loss=182.2638  \t val_acc=0.8740  \t time=215.73s\n",
            "Epoch 4/6 \t loss=164.1148 \t val_loss=182.2516  \t val_acc=0.8733  \t time=217.08s\n",
            "Epoch 4/6 \t loss=165.1652 \t val_loss=182.1086  \t val_acc=0.8732  \t time=218.43s\n",
            "Epoch 4/6 \t loss=166.1652 \t val_loss=182.0829  \t val_acc=0.8740  \t time=219.78s\n",
            "Epoch 4/6 \t loss=167.1981 \t val_loss=181.8105  \t val_acc=0.8737  \t time=221.13s\n",
            "Epoch 4/6 \t loss=168.1687 \t val_loss=181.8684  \t val_acc=0.8737  \t time=222.48s\n",
            "Epoch 4/6 \t loss=168.5925 \t val_loss=182.5131  \t val_acc=0.8732  \t time=223.82s\n",
            "Epoch 5/6 \t loss=1.1591 \t val_loss=182.9720  \t val_acc=0.8731  \t time=1.35s\n",
            "Epoch 5/6 \t loss=2.2230 \t val_loss=183.3891  \t val_acc=0.8740  \t time=2.70s\n",
            "Epoch 5/6 \t loss=3.1624 \t val_loss=183.9598  \t val_acc=0.8733  \t time=4.06s\n",
            "Epoch 5/6 \t loss=4.1251 \t val_loss=184.7426  \t val_acc=0.8721  \t time=5.41s\n",
            "Epoch 5/6 \t loss=5.0423 \t val_loss=185.3778  \t val_acc=0.8713  \t time=6.76s\n",
            "Epoch 5/6 \t loss=6.1006 \t val_loss=185.1850  \t val_acc=0.8717  \t time=8.11s\n",
            "Epoch 5/6 \t loss=7.1238 \t val_loss=183.6186  \t val_acc=0.8726  \t time=9.46s\n",
            "Epoch 5/6 \t loss=8.0108 \t val_loss=182.5779  \t val_acc=0.8738  \t time=11.07s\n",
            "Epoch 5/6 \t loss=8.9099 \t val_loss=183.3138  \t val_acc=0.8723  \t time=12.42s\n",
            "Epoch 5/6 \t loss=9.9485 \t val_loss=184.8092  \t val_acc=0.8711  \t time=13.77s\n",
            "Epoch 5/6 \t loss=10.8206 \t val_loss=185.7464  \t val_acc=0.8695  \t time=15.12s\n",
            "Epoch 5/6 \t loss=11.5900 \t val_loss=184.6479  \t val_acc=0.8704  \t time=16.47s\n",
            "Epoch 5/6 \t loss=12.4150 \t val_loss=182.7390  \t val_acc=0.8726  \t time=17.82s\n",
            "Epoch 5/6 \t loss=13.3158 \t val_loss=181.2788  \t val_acc=0.8731  \t time=19.17s\n",
            "Epoch 5/6 \t loss=14.2869 \t val_loss=180.5706  \t val_acc=0.8746  \t time=20.52s\n",
            "Epoch 5/6 \t loss=15.2322 \t val_loss=181.3360  \t val_acc=0.8751  \t time=21.87s\n",
            "Epoch 5/6 \t loss=16.3049 \t val_loss=182.9209  \t val_acc=0.8725  \t time=23.22s\n",
            "Epoch 5/6 \t loss=17.3231 \t val_loss=184.2600  \t val_acc=0.8715  \t time=24.57s\n",
            "Epoch 5/6 \t loss=18.4143 \t val_loss=184.8427  \t val_acc=0.8709  \t time=25.92s\n",
            "Epoch 5/6 \t loss=19.1891 \t val_loss=184.0644  \t val_acc=0.8723  \t time=27.27s\n",
            "Epoch 5/6 \t loss=20.0344 \t val_loss=183.0234  \t val_acc=0.8734  \t time=28.62s\n",
            "Epoch 5/6 \t loss=21.0122 \t val_loss=182.5404  \t val_acc=0.8730  \t time=29.98s\n",
            "Epoch 5/6 \t loss=21.9539 \t val_loss=182.0359  \t val_acc=0.8732  \t time=31.33s\n",
            "Epoch 5/6 \t loss=22.8663 \t val_loss=181.7184  \t val_acc=0.8725  \t time=32.68s\n",
            "Epoch 5/6 \t loss=23.8205 \t val_loss=181.6964  \t val_acc=0.8718  \t time=34.03s\n",
            "Epoch 5/6 \t loss=24.7715 \t val_loss=180.9642  \t val_acc=0.8727  \t time=35.38s\n",
            "Epoch 5/6 \t loss=25.7357 \t val_loss=180.4765  \t val_acc=0.8748  \t time=36.99s\n",
            "Epoch 5/6 \t loss=26.5593 \t val_loss=180.5350  \t val_acc=0.8738  \t time=38.34s\n",
            "Epoch 5/6 \t loss=27.3838 \t val_loss=180.9015  \t val_acc=0.8742  \t time=39.69s\n",
            "Epoch 5/6 \t loss=28.4178 \t val_loss=181.2674  \t val_acc=0.8735  \t time=41.05s\n",
            "Epoch 5/6 \t loss=29.2785 \t val_loss=181.4383  \t val_acc=0.8736  \t time=42.40s\n",
            "Epoch 5/6 \t loss=30.2484 \t val_loss=181.3239  \t val_acc=0.8739  \t time=43.75s\n",
            "Epoch 5/6 \t loss=31.1450 \t val_loss=180.7453  \t val_acc=0.8742  \t time=45.10s\n",
            "Epoch 5/6 \t loss=32.0989 \t val_loss=180.3709  \t val_acc=0.8743  \t time=46.45s\n",
            "Epoch 5/6 \t loss=32.9618 \t val_loss=180.2081  \t val_acc=0.8742  \t time=47.80s\n",
            "Epoch 5/6 \t loss=33.8383 \t val_loss=180.8780  \t val_acc=0.8736  \t time=49.15s\n",
            "Epoch 5/6 \t loss=34.8268 \t val_loss=181.2470  \t val_acc=0.8742  \t time=50.50s\n",
            "Epoch 5/6 \t loss=35.7290 \t val_loss=181.2601  \t val_acc=0.8742  \t time=51.85s\n",
            "Epoch 5/6 \t loss=36.5909 \t val_loss=180.8649  \t val_acc=0.8745  \t time=53.20s\n",
            "Epoch 5/6 \t loss=37.6460 \t val_loss=180.1774  \t val_acc=0.8748  \t time=54.55s\n",
            "Epoch 5/6 \t loss=38.6590 \t val_loss=179.8545  \t val_acc=0.8753  \t time=55.90s\n",
            "Epoch 5/6 \t loss=39.6187 \t val_loss=179.8137  \t val_acc=0.8754  \t time=57.26s\n",
            "Epoch 5/6 \t loss=40.4844 \t val_loss=180.1733  \t val_acc=0.8757  \t time=58.61s\n",
            "Epoch 5/6 \t loss=41.5249 \t val_loss=180.3768  \t val_acc=0.8756  \t time=59.96s\n",
            "Epoch 5/6 \t loss=42.4557 \t val_loss=180.1818  \t val_acc=0.8758  \t time=61.57s\n",
            "Epoch 5/6 \t loss=43.6234 \t val_loss=179.8638  \t val_acc=0.8757  \t time=62.92s\n",
            "Epoch 5/6 \t loss=44.5094 \t val_loss=179.9782  \t val_acc=0.8756  \t time=64.27s\n",
            "Epoch 5/6 \t loss=45.4388 \t val_loss=180.8120  \t val_acc=0.8748  \t time=65.62s\n",
            "Epoch 5/6 \t loss=46.4113 \t val_loss=182.1546  \t val_acc=0.8737  \t time=66.97s\n",
            "Epoch 5/6 \t loss=47.2774 \t val_loss=182.9571  \t val_acc=0.8727  \t time=68.32s\n",
            "Epoch 5/6 \t loss=48.1576 \t val_loss=182.5334  \t val_acc=0.8731  \t time=69.68s\n",
            "Epoch 5/6 \t loss=49.0033 \t val_loss=181.6606  \t val_acc=0.8743  \t time=71.03s\n",
            "Epoch 5/6 \t loss=49.8761 \t val_loss=180.1390  \t val_acc=0.8748  \t time=72.38s\n",
            "Epoch 5/6 \t loss=50.7427 \t val_loss=180.5917  \t val_acc=0.8742  \t time=73.73s\n",
            "Epoch 5/6 \t loss=51.6393 \t val_loss=181.8944  \t val_acc=0.8729  \t time=75.08s\n",
            "Epoch 5/6 \t loss=52.5797 \t val_loss=182.5818  \t val_acc=0.8716  \t time=76.43s\n",
            "Epoch 5/6 \t loss=53.6556 \t val_loss=180.9806  \t val_acc=0.8734  \t time=77.78s\n",
            "Epoch 5/6 \t loss=54.4758 \t val_loss=179.8096  \t val_acc=0.8744  \t time=79.13s\n",
            "Epoch 5/6 \t loss=55.3523 \t val_loss=179.3607  \t val_acc=0.8750  \t time=80.48s\n",
            "Epoch 5/6 \t loss=56.3998 \t val_loss=179.0547  \t val_acc=0.8750  \t time=81.83s\n",
            "Epoch 5/6 \t loss=57.3505 \t val_loss=179.2616  \t val_acc=0.8762  \t time=83.18s\n",
            "Epoch 5/6 \t loss=58.2293 \t val_loss=179.7136  \t val_acc=0.8764  \t time=84.53s\n",
            "Epoch 5/6 \t loss=59.2521 \t val_loss=179.6997  \t val_acc=0.8758  \t time=86.14s\n",
            "Epoch 5/6 \t loss=60.2680 \t val_loss=179.9243  \t val_acc=0.8757  \t time=87.49s\n",
            "Epoch 5/6 \t loss=61.1736 \t val_loss=179.7077  \t val_acc=0.8752  \t time=88.84s\n",
            "Epoch 5/6 \t loss=61.9618 \t val_loss=179.7645  \t val_acc=0.8736  \t time=90.19s\n",
            "Epoch 5/6 \t loss=62.9651 \t val_loss=179.5060  \t val_acc=0.8739  \t time=91.55s\n",
            "Epoch 5/6 \t loss=63.7973 \t val_loss=179.2169  \t val_acc=0.8744  \t time=92.89s\n",
            "Epoch 5/6 \t loss=64.8785 \t val_loss=178.9090  \t val_acc=0.8751  \t time=94.24s\n",
            "Epoch 5/6 \t loss=65.7963 \t val_loss=178.6672  \t val_acc=0.8750  \t time=95.59s\n",
            "Epoch 5/6 \t loss=66.6400 \t val_loss=178.8922  \t val_acc=0.8754  \t time=96.95s\n",
            "Epoch 5/6 \t loss=67.5974 \t val_loss=179.6762  \t val_acc=0.8738  \t time=98.31s\n",
            "Epoch 5/6 \t loss=68.7891 \t val_loss=179.5226  \t val_acc=0.8746  \t time=99.66s\n",
            "Epoch 5/6 \t loss=69.8689 \t val_loss=179.4360  \t val_acc=0.8749  \t time=101.01s\n",
            "Epoch 5/6 \t loss=70.8223 \t val_loss=179.8976  \t val_acc=0.8744  \t time=102.36s\n",
            "Epoch 5/6 \t loss=71.6600 \t val_loss=180.3085  \t val_acc=0.8753  \t time=103.71s\n",
            "Epoch 5/6 \t loss=72.5883 \t val_loss=180.1473  \t val_acc=0.8748  \t time=105.06s\n",
            "Epoch 5/6 \t loss=73.3666 \t val_loss=179.8609  \t val_acc=0.8739  \t time=106.41s\n",
            "Epoch 5/6 \t loss=74.2300 \t val_loss=179.7481  \t val_acc=0.8724  \t time=107.76s\n",
            "Epoch 5/6 \t loss=75.2688 \t val_loss=179.2592  \t val_acc=0.8730  \t time=109.11s\n",
            "Epoch 5/6 \t loss=76.3220 \t val_loss=178.2252  \t val_acc=0.8747  \t time=110.46s\n",
            "Epoch 5/6 \t loss=77.1979 \t val_loss=177.4804  \t val_acc=0.8746  \t time=112.07s\n",
            "Epoch 5/6 \t loss=78.0431 \t val_loss=177.3645  \t val_acc=0.8757  \t time=113.42s\n",
            "Epoch 5/6 \t loss=78.7981 \t val_loss=177.9269  \t val_acc=0.8763  \t time=114.77s\n",
            "Epoch 5/6 \t loss=79.8014 \t val_loss=178.7709  \t val_acc=0.8750  \t time=116.12s\n",
            "Epoch 5/6 \t loss=80.8968 \t val_loss=179.0244  \t val_acc=0.8747  \t time=117.47s\n",
            "Epoch 5/6 \t loss=81.9500 \t val_loss=179.1948  \t val_acc=0.8755  \t time=118.83s\n",
            "Epoch 5/6 \t loss=82.9782 \t val_loss=178.6141  \t val_acc=0.8768  \t time=120.18s\n",
            "Epoch 5/6 \t loss=83.9095 \t val_loss=177.9207  \t val_acc=0.8776  \t time=121.53s\n",
            "Epoch 5/6 \t loss=84.9284 \t val_loss=177.4702  \t val_acc=0.8774  \t time=122.88s\n",
            "Epoch 5/6 \t loss=85.8406 \t val_loss=177.3589  \t val_acc=0.8765  \t time=124.23s\n",
            "Epoch 5/6 \t loss=86.6576 \t val_loss=177.3898  \t val_acc=0.8765  \t time=125.58s\n",
            "Epoch 5/6 \t loss=87.6313 \t val_loss=177.4683  \t val_acc=0.8761  \t time=126.93s\n",
            "Epoch 5/6 \t loss=88.8140 \t val_loss=177.4154  \t val_acc=0.8762  \t time=128.28s\n",
            "Epoch 5/6 \t loss=89.9673 \t val_loss=177.2071  \t val_acc=0.8759  \t time=129.62s\n",
            "Epoch 5/6 \t loss=90.8730 \t val_loss=177.1296  \t val_acc=0.8761  \t time=130.98s\n",
            "Epoch 5/6 \t loss=91.7642 \t val_loss=177.0154  \t val_acc=0.8761  \t time=132.33s\n",
            "Epoch 5/6 \t loss=92.7040 \t val_loss=176.8300  \t val_acc=0.8762  \t time=133.68s\n",
            "Epoch 5/6 \t loss=93.4643 \t val_loss=176.5262  \t val_acc=0.8771  \t time=135.02s\n",
            "Epoch 5/6 \t loss=94.4935 \t val_loss=176.3457  \t val_acc=0.8773  \t time=136.65s\n",
            "Epoch 5/6 \t loss=95.2447 \t val_loss=176.6542  \t val_acc=0.8782  \t time=138.00s\n",
            "Epoch 5/6 \t loss=96.2370 \t val_loss=177.4778  \t val_acc=0.8770  \t time=139.36s\n",
            "Epoch 5/6 \t loss=97.0823 \t val_loss=178.0817  \t val_acc=0.8767  \t time=140.71s\n",
            "Epoch 5/6 \t loss=97.9771 \t val_loss=177.6979  \t val_acc=0.8771  \t time=142.06s\n",
            "Epoch 5/6 \t loss=98.8862 \t val_loss=176.8439  \t val_acc=0.8780  \t time=143.41s\n",
            "Epoch 5/6 \t loss=99.9704 \t val_loss=176.1882  \t val_acc=0.8787  \t time=144.76s\n",
            "Epoch 5/6 \t loss=100.7063 \t val_loss=176.0522  \t val_acc=0.8781  \t time=146.11s\n",
            "Epoch 5/6 \t loss=101.5805 \t val_loss=176.9152  \t val_acc=0.8780  \t time=147.47s\n",
            "Epoch 5/6 \t loss=102.3886 \t val_loss=178.2531  \t val_acc=0.8773  \t time=148.82s\n",
            "Epoch 5/6 \t loss=103.3127 \t val_loss=178.4743  \t val_acc=0.8769  \t time=150.17s\n",
            "Epoch 5/6 \t loss=104.2544 \t val_loss=178.2788  \t val_acc=0.8767  \t time=151.52s\n",
            "Epoch 5/6 \t loss=105.0656 \t val_loss=177.4889  \t val_acc=0.8772  \t time=152.87s\n",
            "Epoch 5/6 \t loss=106.0704 \t val_loss=176.5823  \t val_acc=0.8776  \t time=154.22s\n",
            "Epoch 5/6 \t loss=106.9256 \t val_loss=176.0190  \t val_acc=0.8773  \t time=155.57s\n",
            "Epoch 5/6 \t loss=107.7856 \t val_loss=176.1721  \t val_acc=0.8764  \t time=156.93s\n",
            "Epoch 5/6 \t loss=108.7107 \t val_loss=176.1377  \t val_acc=0.8763  \t time=158.28s\n",
            "Epoch 5/6 \t loss=109.6031 \t val_loss=176.0765  \t val_acc=0.8762  \t time=159.63s\n",
            "Epoch 5/6 \t loss=110.4650 \t val_loss=175.8677  \t val_acc=0.8764  \t time=160.98s\n",
            "Epoch 5/6 \t loss=111.4768 \t val_loss=175.6242  \t val_acc=0.8771  \t time=162.60s\n",
            "Epoch 5/6 \t loss=112.3797 \t val_loss=175.8397  \t val_acc=0.8781  \t time=163.95s\n",
            "Epoch 5/6 \t loss=113.3390 \t val_loss=176.2625  \t val_acc=0.8773  \t time=165.30s\n",
            "Epoch 5/6 \t loss=114.2534 \t val_loss=176.5511  \t val_acc=0.8762  \t time=166.65s\n",
            "Epoch 5/6 \t loss=115.2046 \t val_loss=176.2580  \t val_acc=0.8764  \t time=168.00s\n",
            "Epoch 5/6 \t loss=115.9117 \t val_loss=175.6377  \t val_acc=0.8766  \t time=169.36s\n",
            "Epoch 5/6 \t loss=116.9646 \t val_loss=175.4905  \t val_acc=0.8780  \t time=170.71s\n",
            "Epoch 5/6 \t loss=117.8758 \t val_loss=175.8002  \t val_acc=0.8780  \t time=172.06s\n",
            "Epoch 5/6 \t loss=118.7681 \t val_loss=175.9391  \t val_acc=0.8784  \t time=173.41s\n",
            "Epoch 5/6 \t loss=119.6823 \t val_loss=176.2432  \t val_acc=0.8783  \t time=174.75s\n",
            "Epoch 5/6 \t loss=120.5018 \t val_loss=176.5678  \t val_acc=0.8779  \t time=176.10s\n",
            "Epoch 5/6 \t loss=121.3776 \t val_loss=176.6696  \t val_acc=0.8786  \t time=177.46s\n",
            "Epoch 5/6 \t loss=122.4536 \t val_loss=176.5774  \t val_acc=0.8778  \t time=178.82s\n",
            "Epoch 5/6 \t loss=123.3249 \t val_loss=176.3287  \t val_acc=0.8778  \t time=180.17s\n",
            "Epoch 5/6 \t loss=124.2169 \t val_loss=176.0083  \t val_acc=0.8782  \t time=181.52s\n",
            "Epoch 5/6 \t loss=125.0028 \t val_loss=175.8187  \t val_acc=0.8772  \t time=182.87s\n",
            "Epoch 5/6 \t loss=125.9939 \t val_loss=175.4199  \t val_acc=0.8775  \t time=184.22s\n",
            "Epoch 5/6 \t loss=126.8693 \t val_loss=174.7153  \t val_acc=0.8775  \t time=185.57s\n",
            "Epoch 5/6 \t loss=127.7861 \t val_loss=174.3150  \t val_acc=0.8789  \t time=186.92s\n",
            "Epoch 5/6 \t loss=128.6148 \t val_loss=174.3770  \t val_acc=0.8797  \t time=188.53s\n",
            "Epoch 5/6 \t loss=129.3938 \t val_loss=175.0006  \t val_acc=0.8783  \t time=189.88s\n",
            "Epoch 5/6 \t loss=130.4338 \t val_loss=176.0451  \t val_acc=0.8777  \t time=191.24s\n",
            "Epoch 5/6 \t loss=131.4678 \t val_loss=176.1464  \t val_acc=0.8780  \t time=192.59s\n",
            "Epoch 5/6 \t loss=132.4037 \t val_loss=175.4404  \t val_acc=0.8785  \t time=193.94s\n",
            "Epoch 5/6 \t loss=133.2721 \t val_loss=175.0329  \t val_acc=0.8789  \t time=195.29s\n",
            "Epoch 5/6 \t loss=134.3243 \t val_loss=175.0456  \t val_acc=0.8787  \t time=196.64s\n",
            "Epoch 5/6 \t loss=135.3259 \t val_loss=174.4847  \t val_acc=0.8782  \t time=197.99s\n",
            "Epoch 5/6 \t loss=136.2668 \t val_loss=174.1254  \t val_acc=0.8784  \t time=199.34s\n",
            "Epoch 5/6 \t loss=137.1596 \t val_loss=173.9737  \t val_acc=0.8793  \t time=200.69s\n",
            "Epoch 5/6 \t loss=138.1670 \t val_loss=174.6439  \t val_acc=0.8782  \t time=202.04s\n",
            "Epoch 5/6 \t loss=139.0487 \t val_loss=175.6608  \t val_acc=0.8773  \t time=203.39s\n",
            "Epoch 5/6 \t loss=139.8837 \t val_loss=176.8623  \t val_acc=0.8752  \t time=204.74s\n",
            "Epoch 5/6 \t loss=140.6864 \t val_loss=177.3002  \t val_acc=0.8755  \t time=206.10s\n",
            "Epoch 5/6 \t loss=141.4408 \t val_loss=176.1527  \t val_acc=0.8770  \t time=207.45s\n",
            "Epoch 5/6 \t loss=142.3997 \t val_loss=174.8707  \t val_acc=0.8784  \t time=208.80s\n",
            "Epoch 5/6 \t loss=143.3201 \t val_loss=173.5374  \t val_acc=0.8792  \t time=210.15s\n",
            "Epoch 5/6 \t loss=144.1553 \t val_loss=172.9204  \t val_acc=0.8801  \t time=211.50s\n",
            "Epoch 5/6 \t loss=145.1016 \t val_loss=173.1752  \t val_acc=0.8797  \t time=213.11s\n",
            "Epoch 5/6 \t loss=145.9958 \t val_loss=173.6437  \t val_acc=0.8793  \t time=214.46s\n",
            "Epoch 5/6 \t loss=146.9399 \t val_loss=173.9221  \t val_acc=0.8793  \t time=215.81s\n",
            "Epoch 5/6 \t loss=147.8112 \t val_loss=173.8403  \t val_acc=0.8796  \t time=217.16s\n",
            "Epoch 5/6 \t loss=148.5860 \t val_loss=173.6749  \t val_acc=0.8800  \t time=218.52s\n",
            "Epoch 5/6 \t loss=149.4996 \t val_loss=173.4837  \t val_acc=0.8797  \t time=219.87s\n",
            "Epoch 5/6 \t loss=150.5685 \t val_loss=173.2922  \t val_acc=0.8797  \t time=221.22s\n",
            "Epoch 5/6 \t loss=151.5098 \t val_loss=173.5692  \t val_acc=0.8790  \t time=222.57s\n",
            "Epoch 5/6 \t loss=151.9238 \t val_loss=174.1671  \t val_acc=0.8780  \t time=223.90s\n",
            "Epoch 6/6 \t loss=0.9400 \t val_loss=174.6338  \t val_acc=0.8772  \t time=1.36s\n",
            "Epoch 6/6 \t loss=1.8370 \t val_loss=174.2793  \t val_acc=0.8771  \t time=2.71s\n",
            "Epoch 6/6 \t loss=2.6453 \t val_loss=173.9266  \t val_acc=0.8778  \t time=4.06s\n",
            "Epoch 6/6 \t loss=3.6811 \t val_loss=173.1357  \t val_acc=0.8784  \t time=5.41s\n",
            "Epoch 6/6 \t loss=4.3868 \t val_loss=173.0607  \t val_acc=0.8791  \t time=6.76s\n",
            "Epoch 6/6 \t loss=5.2660 \t val_loss=172.7535  \t val_acc=0.8804  \t time=8.11s\n",
            "Epoch 6/6 \t loss=6.1424 \t val_loss=172.7223  \t val_acc=0.8810  \t time=9.47s\n",
            "Epoch 6/6 \t loss=7.1260 \t val_loss=172.7254  \t val_acc=0.8810  \t time=10.82s\n",
            "Epoch 6/6 \t loss=7.9277 \t val_loss=172.8188  \t val_acc=0.8818  \t time=12.17s\n",
            "Epoch 6/6 \t loss=8.7963 \t val_loss=173.1208  \t val_acc=0.8811  \t time=13.52s\n",
            "Epoch 6/6 \t loss=9.5890 \t val_loss=173.4805  \t val_acc=0.8804  \t time=15.14s\n",
            "Epoch 6/6 \t loss=10.4524 \t val_loss=173.4503  \t val_acc=0.8811  \t time=16.48s\n",
            "Epoch 6/6 \t loss=11.2228 \t val_loss=173.3045  \t val_acc=0.8809  \t time=17.84s\n",
            "Epoch 6/6 \t loss=12.0238 \t val_loss=173.1497  \t val_acc=0.8813  \t time=19.19s\n",
            "Epoch 6/6 \t loss=12.9240 \t val_loss=172.7181  \t val_acc=0.8813  \t time=20.54s\n",
            "Epoch 6/6 \t loss=13.7397 \t val_loss=172.3849  \t val_acc=0.8811  \t time=21.91s\n",
            "Epoch 6/6 \t loss=14.4706 \t val_loss=172.0758  \t val_acc=0.8811  \t time=23.26s\n",
            "Epoch 6/6 \t loss=15.3119 \t val_loss=172.2977  \t val_acc=0.8806  \t time=24.61s\n",
            "Epoch 6/6 \t loss=16.2054 \t val_loss=172.4365  \t val_acc=0.8805  \t time=25.96s\n",
            "Epoch 6/6 \t loss=17.0076 \t val_loss=172.2403  \t val_acc=0.8808  \t time=27.31s\n",
            "Epoch 6/6 \t loss=17.8213 \t val_loss=172.0297  \t val_acc=0.8810  \t time=28.67s\n",
            "Epoch 6/6 \t loss=18.6875 \t val_loss=172.0653  \t val_acc=0.8806  \t time=30.02s\n",
            "Epoch 6/6 \t loss=19.5050 \t val_loss=172.1038  \t val_acc=0.8801  \t time=31.38s\n",
            "Epoch 6/6 \t loss=20.3174 \t val_loss=172.3565  \t val_acc=0.8803  \t time=32.73s\n",
            "Epoch 6/6 \t loss=21.0974 \t val_loss=172.7730  \t val_acc=0.8794  \t time=34.08s\n",
            "Epoch 6/6 \t loss=21.9707 \t val_loss=173.3550  \t val_acc=0.8791  \t time=35.43s\n",
            "Epoch 6/6 \t loss=22.7342 \t val_loss=174.0684  \t val_acc=0.8794  \t time=36.78s\n",
            "Epoch 6/6 \t loss=23.5337 \t val_loss=174.2624  \t val_acc=0.8794  \t time=38.13s\n",
            "Epoch 6/6 \t loss=24.2845 \t val_loss=174.2653  \t val_acc=0.8790  \t time=39.48s\n",
            "Epoch 6/6 \t loss=25.0926 \t val_loss=173.4706  \t val_acc=0.8806  \t time=41.09s\n",
            "Epoch 6/6 \t loss=25.9666 \t val_loss=172.6119  \t val_acc=0.8806  \t time=42.44s\n",
            "Epoch 6/6 \t loss=26.8161 \t val_loss=171.8816  \t val_acc=0.8806  \t time=43.79s\n",
            "Epoch 6/6 \t loss=27.6056 \t val_loss=171.9723  \t val_acc=0.8820  \t time=45.14s\n",
            "Epoch 6/6 \t loss=28.3667 \t val_loss=171.8506  \t val_acc=0.8824  \t time=46.49s\n",
            "Epoch 6/6 \t loss=29.0709 \t val_loss=172.2710  \t val_acc=0.8801  \t time=47.84s\n",
            "Epoch 6/6 \t loss=29.9137 \t val_loss=172.7396  \t val_acc=0.8794  \t time=49.19s\n",
            "Epoch 6/6 \t loss=30.7426 \t val_loss=172.6613  \t val_acc=0.8790  \t time=50.54s\n",
            "Epoch 6/6 \t loss=31.5699 \t val_loss=172.3839  \t val_acc=0.8794  \t time=51.89s\n",
            "Epoch 6/6 \t loss=32.3240 \t val_loss=171.9435  \t val_acc=0.8811  \t time=53.24s\n",
            "Epoch 6/6 \t loss=33.1673 \t val_loss=172.1594  \t val_acc=0.8809  \t time=54.60s\n",
            "Epoch 6/6 \t loss=33.9204 \t val_loss=172.6680  \t val_acc=0.8811  \t time=55.95s\n",
            "Epoch 6/6 \t loss=34.7135 \t val_loss=173.3262  \t val_acc=0.8803  \t time=57.30s\n",
            "Epoch 6/6 \t loss=35.3976 \t val_loss=174.3462  \t val_acc=0.8798  \t time=58.65s\n",
            "Epoch 6/6 \t loss=36.4313 \t val_loss=175.2782  \t val_acc=0.8790  \t time=60.00s\n",
            "Epoch 6/6 \t loss=37.2539 \t val_loss=174.7981  \t val_acc=0.8788  \t time=61.35s\n",
            "Epoch 6/6 \t loss=38.0439 \t val_loss=173.8544  \t val_acc=0.8793  \t time=62.70s\n",
            "Epoch 6/6 \t loss=38.8504 \t val_loss=173.8133  \t val_acc=0.8808  \t time=64.05s\n",
            "Epoch 6/6 \t loss=39.6306 \t val_loss=173.2830  \t val_acc=0.8811  \t time=65.68s\n",
            "Epoch 6/6 \t loss=40.4921 \t val_loss=173.5532  \t val_acc=0.8801  \t time=67.03s\n",
            "Epoch 6/6 \t loss=41.4214 \t val_loss=172.7887  \t val_acc=0.8809  \t time=68.38s\n",
            "Epoch 6/6 \t loss=42.1924 \t val_loss=172.4018  \t val_acc=0.8806  \t time=69.73s\n",
            "Epoch 6/6 \t loss=43.0190 \t val_loss=172.2904  \t val_acc=0.8814  \t time=71.08s\n",
            "Epoch 6/6 \t loss=43.8112 \t val_loss=171.6233  \t val_acc=0.8811  \t time=72.43s\n",
            "Epoch 6/6 \t loss=44.4284 \t val_loss=171.0540  \t val_acc=0.8815  \t time=73.80s\n",
            "Epoch 6/6 \t loss=45.1537 \t val_loss=170.5154  \t val_acc=0.8818  \t time=75.15s\n",
            "Epoch 6/6 \t loss=46.0489 \t val_loss=170.3974  \t val_acc=0.8817  \t time=76.50s\n",
            "Epoch 6/6 \t loss=46.9277 \t val_loss=170.7905  \t val_acc=0.8817  \t time=77.85s\n",
            "Epoch 6/6 \t loss=47.7931 \t val_loss=171.4178  \t val_acc=0.8818  \t time=79.20s\n",
            "Epoch 6/6 \t loss=48.5663 \t val_loss=172.5403  \t val_acc=0.8805  \t time=80.55s\n",
            "Epoch 6/6 \t loss=49.4956 \t val_loss=173.0670  \t val_acc=0.8799  \t time=81.90s\n",
            "Epoch 6/6 \t loss=50.2093 \t val_loss=173.2623  \t val_acc=0.8811  \t time=83.25s\n",
            "Epoch 6/6 \t loss=51.1540 \t val_loss=172.8723  \t val_acc=0.8816  \t time=84.60s\n",
            "Epoch 6/6 \t loss=52.0397 \t val_loss=172.3458  \t val_acc=0.8815  \t time=85.95s\n",
            "Epoch 6/6 \t loss=52.9020 \t val_loss=172.0903  \t val_acc=0.8826  \t time=87.30s\n",
            "Epoch 6/6 \t loss=53.8017 \t val_loss=172.5608  \t val_acc=0.8811  \t time=88.65s\n",
            "Epoch 6/6 \t loss=54.6776 \t val_loss=173.1587  \t val_acc=0.8813  \t time=90.00s\n",
            "Epoch 6/6 \t loss=55.5478 \t val_loss=173.7864  \t val_acc=0.8809  \t time=91.62s\n",
            "Epoch 6/6 \t loss=56.3974 \t val_loss=174.3995  \t val_acc=0.8802  \t time=92.98s\n",
            "Epoch 6/6 \t loss=57.1301 \t val_loss=174.2562  \t val_acc=0.8806  \t time=94.33s\n",
            "Epoch 6/6 \t loss=57.9582 \t val_loss=172.6304  \t val_acc=0.8807  \t time=95.68s\n",
            "Epoch 6/6 \t loss=58.7526 \t val_loss=171.2826  \t val_acc=0.8820  \t time=97.03s\n",
            "Epoch 6/6 \t loss=59.7039 \t val_loss=170.7265  \t val_acc=0.8828  \t time=98.38s\n",
            "Epoch 6/6 \t loss=60.6221 \t val_loss=171.2200  \t val_acc=0.8819  \t time=99.73s\n",
            "Epoch 6/6 \t loss=61.5409 \t val_loss=172.5659  \t val_acc=0.8811  \t time=101.08s\n",
            "Epoch 6/6 \t loss=62.4883 \t val_loss=173.7318  \t val_acc=0.8803  \t time=102.43s\n",
            "Epoch 6/6 \t loss=63.3034 \t val_loss=173.8202  \t val_acc=0.8802  \t time=103.78s\n",
            "Epoch 6/6 \t loss=64.2058 \t val_loss=172.9077  \t val_acc=0.8806  \t time=105.13s\n",
            "Epoch 6/6 \t loss=65.0120 \t val_loss=171.9221  \t val_acc=0.8802  \t time=106.48s\n",
            "Epoch 6/6 \t loss=65.8183 \t val_loss=171.2193  \t val_acc=0.8812  \t time=107.83s\n",
            "Epoch 6/6 \t loss=66.7192 \t val_loss=171.2996  \t val_acc=0.8813  \t time=109.18s\n",
            "Epoch 6/6 \t loss=67.4802 \t val_loss=171.9293  \t val_acc=0.8800  \t time=110.53s\n",
            "Epoch 6/6 \t loss=68.2068 \t val_loss=172.3356  \t val_acc=0.8802  \t time=111.88s\n",
            "Epoch 6/6 \t loss=68.9934 \t val_loss=172.9364  \t val_acc=0.8806  \t time=113.23s\n",
            "Epoch 6/6 \t loss=69.7303 \t val_loss=173.2305  \t val_acc=0.8804  \t time=114.58s\n",
            "Epoch 6/6 \t loss=70.5362 \t val_loss=172.6496  \t val_acc=0.8803  \t time=115.93s\n",
            "Epoch 6/6 \t loss=71.3432 \t val_loss=171.4241  \t val_acc=0.8809  \t time=117.55s\n",
            "Epoch 6/6 \t loss=72.1278 \t val_loss=170.4617  \t val_acc=0.8818  \t time=118.90s\n",
            "Epoch 6/6 \t loss=73.0222 \t val_loss=170.5922  \t val_acc=0.8834  \t time=120.25s\n",
            "Epoch 6/6 \t loss=73.9080 \t val_loss=170.8646  \t val_acc=0.8837  \t time=121.61s\n",
            "Epoch 6/6 \t loss=74.9479 \t val_loss=170.7839  \t val_acc=0.8821  \t time=122.96s\n",
            "Epoch 6/6 \t loss=75.6609 \t val_loss=170.1905  \t val_acc=0.8824  \t time=124.31s\n",
            "Epoch 6/6 \t loss=76.6112 \t val_loss=169.7516  \t val_acc=0.8830  \t time=125.66s\n",
            "Epoch 6/6 \t loss=77.4656 \t val_loss=169.3879  \t val_acc=0.8825  \t time=127.01s\n",
            "Epoch 6/6 \t loss=78.3106 \t val_loss=169.5516  \t val_acc=0.8824  \t time=128.36s\n",
            "Epoch 6/6 \t loss=79.3280 \t val_loss=169.8806  \t val_acc=0.8827  \t time=129.71s\n",
            "Epoch 6/6 \t loss=80.1678 \t val_loss=170.1636  \t val_acc=0.8820  \t time=131.06s\n",
            "Epoch 6/6 \t loss=80.8993 \t val_loss=170.2350  \t val_acc=0.8816  \t time=132.41s\n",
            "Epoch 6/6 \t loss=81.7594 \t val_loss=169.9913  \t val_acc=0.8815  \t time=133.76s\n",
            "Epoch 6/6 \t loss=82.5815 \t val_loss=169.3251  \t val_acc=0.8836  \t time=135.11s\n",
            "Epoch 6/6 \t loss=83.5785 \t val_loss=169.3602  \t val_acc=0.8835  \t time=136.46s\n",
            "Epoch 6/6 \t loss=84.3995 \t val_loss=169.9635  \t val_acc=0.8830  \t time=137.81s\n",
            "Epoch 6/6 \t loss=85.2706 \t val_loss=170.5468  \t val_acc=0.8816  \t time=139.16s\n",
            "Epoch 6/6 \t loss=86.0926 \t val_loss=170.3729  \t val_acc=0.8819  \t time=140.51s\n",
            "Epoch 6/6 \t loss=86.8390 \t val_loss=170.0857  \t val_acc=0.8835  \t time=142.12s\n",
            "Epoch 6/6 \t loss=87.7404 \t val_loss=169.9093  \t val_acc=0.8839  \t time=143.47s\n",
            "Epoch 6/6 \t loss=88.5780 \t val_loss=170.3147  \t val_acc=0.8821  \t time=144.82s\n",
            "Epoch 6/6 \t loss=89.3395 \t val_loss=171.1279  \t val_acc=0.8819  \t time=146.17s\n",
            "Epoch 6/6 \t loss=90.3319 \t val_loss=171.0427  \t val_acc=0.8813  \t time=147.52s\n",
            "Epoch 6/6 \t loss=91.2528 \t val_loss=170.4403  \t val_acc=0.8810  \t time=148.87s\n",
            "Epoch 6/6 \t loss=92.0622 \t val_loss=169.4947  \t val_acc=0.8825  \t time=150.22s\n",
            "Epoch 6/6 \t loss=92.8488 \t val_loss=168.9413  \t val_acc=0.8827  \t time=151.57s\n",
            "Epoch 6/6 \t loss=93.7007 \t val_loss=168.6857  \t val_acc=0.8831  \t time=152.92s\n",
            "Epoch 6/6 \t loss=94.4926 \t val_loss=168.8869  \t val_acc=0.8833  \t time=154.26s\n",
            "Epoch 6/6 \t loss=95.2806 \t val_loss=169.5644  \t val_acc=0.8829  \t time=155.61s\n",
            "Epoch 6/6 \t loss=96.0194 \t val_loss=170.0592  \t val_acc=0.8828  \t time=156.96s\n",
            "Epoch 6/6 \t loss=96.9943 \t val_loss=170.3140  \t val_acc=0.8829  \t time=158.31s\n",
            "Epoch 6/6 \t loss=97.6979 \t val_loss=170.3666  \t val_acc=0.8824  \t time=159.66s\n",
            "Epoch 6/6 \t loss=98.6309 \t val_loss=169.6161  \t val_acc=0.8827  \t time=161.01s\n",
            "Epoch 6/6 \t loss=99.5551 \t val_loss=168.9936  \t val_acc=0.8827  \t time=162.36s\n",
            "Epoch 6/6 \t loss=100.3895 \t val_loss=168.8719  \t val_acc=0.8830  \t time=163.71s\n",
            "Epoch 6/6 \t loss=101.4179 \t val_loss=169.0459  \t val_acc=0.8825  \t time=165.06s\n",
            "Epoch 6/6 \t loss=102.2421 \t val_loss=168.6451  \t val_acc=0.8837  \t time=166.41s\n",
            "Epoch 6/6 \t loss=103.0135 \t val_loss=168.8825  \t val_acc=0.8833  \t time=168.02s\n",
            "Epoch 6/6 \t loss=103.6593 \t val_loss=170.7071  \t val_acc=0.8816  \t time=169.36s\n",
            "Epoch 6/6 \t loss=104.5983 \t val_loss=172.3495  \t val_acc=0.8807  \t time=170.72s\n",
            "Epoch 6/6 \t loss=105.4275 \t val_loss=171.9373  \t val_acc=0.8806  \t time=172.07s\n",
            "Epoch 6/6 \t loss=106.3454 \t val_loss=171.4271  \t val_acc=0.8792  \t time=173.43s\n",
            "Epoch 6/6 \t loss=107.2690 \t val_loss=171.8853  \t val_acc=0.8771  \t time=174.78s\n",
            "Epoch 6/6 \t loss=108.0820 \t val_loss=173.3728  \t val_acc=0.8752  \t time=176.13s\n",
            "Epoch 6/6 \t loss=108.9701 \t val_loss=173.1033  \t val_acc=0.8750  \t time=177.48s\n",
            "Epoch 6/6 \t loss=109.8732 \t val_loss=170.0287  \t val_acc=0.8798  \t time=178.83s\n",
            "Epoch 6/6 \t loss=110.8655 \t val_loss=167.8671  \t val_acc=0.8824  \t time=180.18s\n",
            "Epoch 6/6 \t loss=111.6695 \t val_loss=167.5450  \t val_acc=0.8837  \t time=181.53s\n",
            "Epoch 6/6 \t loss=112.4740 \t val_loss=169.0724  \t val_acc=0.8831  \t time=182.88s\n",
            "Epoch 6/6 \t loss=113.5327 \t val_loss=170.6245  \t val_acc=0.8818  \t time=184.23s\n",
            "Epoch 6/6 \t loss=114.2213 \t val_loss=172.0234  \t val_acc=0.8796  \t time=185.58s\n",
            "Epoch 6/6 \t loss=115.0758 \t val_loss=172.1389  \t val_acc=0.8788  \t time=186.93s\n",
            "Epoch 6/6 \t loss=115.8811 \t val_loss=170.6602  \t val_acc=0.8805  \t time=188.28s\n",
            "Epoch 6/6 \t loss=116.6816 \t val_loss=168.5633  \t val_acc=0.8828  \t time=189.63s\n",
            "Epoch 6/6 \t loss=117.6205 \t val_loss=167.2769  \t val_acc=0.8835  \t time=190.99s\n",
            "Epoch 6/6 \t loss=118.5699 \t val_loss=169.6299  \t val_acc=0.8814  \t time=192.34s\n",
            "Epoch 6/6 \t loss=119.3916 \t val_loss=172.4750  \t val_acc=0.8782  \t time=193.95s\n",
            "Epoch 6/6 \t loss=120.2365 \t val_loss=173.5718  \t val_acc=0.8775  \t time=195.30s\n",
            "Epoch 6/6 \t loss=121.1378 \t val_loss=170.5398  \t val_acc=0.8809  \t time=196.65s\n",
            "Epoch 6/6 \t loss=122.0059 \t val_loss=167.8140  \t val_acc=0.8830  \t time=198.00s\n",
            "Epoch 6/6 \t loss=122.8578 \t val_loss=167.4631  \t val_acc=0.8843  \t time=199.36s\n",
            "Epoch 6/6 \t loss=123.7767 \t val_loss=168.1200  \t val_acc=0.8841  \t time=200.71s\n",
            "Epoch 6/6 \t loss=124.5734 \t val_loss=168.9231  \t val_acc=0.8835  \t time=202.06s\n",
            "Epoch 6/6 \t loss=125.6447 \t val_loss=169.8501  \t val_acc=0.8820  \t time=203.41s\n",
            "Epoch 6/6 \t loss=126.4630 \t val_loss=169.1797  \t val_acc=0.8827  \t time=204.76s\n",
            "Epoch 6/6 \t loss=127.3714 \t val_loss=167.7415  \t val_acc=0.8836  \t time=206.11s\n",
            "Epoch 6/6 \t loss=128.3036 \t val_loss=166.7138  \t val_acc=0.8840  \t time=207.46s\n",
            "Epoch 6/6 \t loss=129.2164 \t val_loss=166.6970  \t val_acc=0.8830  \t time=208.81s\n",
            "Epoch 6/6 \t loss=130.0275 \t val_loss=167.4877  \t val_acc=0.8829  \t time=210.16s\n",
            "Epoch 6/6 \t loss=130.9609 \t val_loss=168.5002  \t val_acc=0.8819  \t time=211.52s\n",
            "Epoch 6/6 \t loss=131.7044 \t val_loss=168.6164  \t val_acc=0.8816  \t time=212.87s\n",
            "Epoch 6/6 \t loss=132.6015 \t val_loss=167.8583  \t val_acc=0.8830  \t time=214.22s\n",
            "Epoch 6/6 \t loss=133.3553 \t val_loss=167.0989  \t val_acc=0.8843  \t time=215.57s\n",
            "Epoch 6/6 \t loss=134.4687 \t val_loss=166.5869  \t val_acc=0.8844  \t time=216.92s\n",
            "Epoch 6/6 \t loss=135.3784 \t val_loss=166.8564  \t val_acc=0.8848  \t time=218.52s\n",
            "Epoch 6/6 \t loss=136.1242 \t val_loss=167.2843  \t val_acc=0.8843  \t time=219.87s\n",
            "Epoch 6/6 \t loss=136.7952 \t val_loss=167.5308  \t val_acc=0.8837  \t time=221.22s\n",
            "Epoch 6/6 \t loss=137.4607 \t val_loss=167.9338  \t val_acc=0.8831  \t time=222.58s\n",
            "Epoch 6/6 \t loss=137.8679 \t val_loss=167.8785  \t val_acc=0.8840  \t time=223.91s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'textcnn_model')"
      ],
      "metadata": {
        "id": "E-UURJafbHwC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "-vfqyFMkivzt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(n_epochs)"
      ],
      "metadata": {
        "id": "Z0kuIkEEjeh-",
        "outputId": "c82138bf-77ff-4a34-989f-b0ca5979faac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-75b6a5720167>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-0035e189e00b>\u001b[0m in \u001b[0;36mplot_graph\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train/Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (6,) and (984,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HrH7B87jjhvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}