{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArslanAmanov/AI-ML-DL/blob/default-branch/ML_models%20research%20notebooks/LGBM_research%20%26%20review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LGBM Model Research\n",
        "\n",
        "LightGBM( Light Gradient Boosting Machine) is a popular gradient boosting framework for machine learning tasks, especially in the field of tabular data.\n",
        "It was developed by Microsoft and is known for its efficiency, speed and ability to handle large datasets.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_vUH6NfIwnCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting overview:\n",
        "\n",
        "Gradient boosting is an ensemble learning technique used for both classification and regression tasks. It builds of decision trees sequentially, where each tree corrects the errors made by the previous one."
      ],
      "metadata": {
        "id": "DwSekPM0yjCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step by Step process of gradient boosting:\n",
        "\n",
        "1. Start with an initial prediction(usually the mean of the target values for regression or a balanced class distribution for classification).\n",
        "2. Calculate the residuals (the difference between the actual and predicted values) for each data point.\n",
        "3. Fit a decision tree to the residuals. This tree is often referred to as a \"weak learner\" because it's simple model.\n",
        "4. Add the predictions from the new tree to the previous predictions, which updates the model's predictions.\n",
        "5. Repeat steps 2-4 for a special number of iterations or until a predefined stopping criterion is met.\n",
        "6. The final ensemble model is the sum of all the predictions from the individual trees."
      ],
      "metadata": {
        "id": "-SHasvYjzEuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LGBM Features:\n",
        "LightGBM offers several features and optimizations that make it stand out:\n",
        "\n",
        "1."
      ],
      "metadata": {
        "id": "2NCPYA7T0hsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlCHh9sl0uml"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}